{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e86a2b3",
   "metadata": {},
   "source": [
    "# NeMo ASR Training Using AWS SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215e3d3c",
   "metadata": {},
   "source": [
    "In this tutorial we show how you can train a NeMo ASR Model using [Amazon SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html). This is meant to be a minimalistic example of how to use SageMaker with NeMo.\n",
    "\n",
    "AWS SageMaker is useful for practioners/researchers who are familiar with training locally or on a remote instance (via SSH). SageMaker also supports multi-GPU & Multi-node.\n",
    "\n",
    "Using AWS SageMaker we train a simple Conformer CTC model using the AN4 dataset on a remote instance with a GPU (p3.2xlarge). We use S3 to store the data and our checkpoints/logs.\n",
    "\n",
    "The overall steps are:\n",
    "\n",
    "1. Setup your AWS Credentials to access SageMaker\n",
    "2. Download the source code we'll be running\n",
    "3. Setup AN4 dataset, upload data to S3\n",
    "4. Configure the training job\n",
    "5. Run training job on SageMaker\n",
    "6. Download model, (Optional) Tensorboard Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67871b86-976f-4cde-af0f-6ad44f643cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "install_needed = True  # should only be True once\n",
    "# install_needed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b8a5c-4ff5-482e-b0d2-d6f456f2f96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#!/bin/bash\n",
    "\n",
    "DAEMON_PATH=\"/etc/docker\"\n",
    "MEMORY_SIZE=10G\n",
    "\n",
    "FLAG=$(cat $DAEMON_PATH/daemon.json | jq 'has(\"data-root\")')\n",
    "# echo $FLAG\n",
    "\n",
    "if [ \"$FLAG\" == true ]; then\n",
    "    echo \"Already revised\"\n",
    "else\n",
    "    echo \"Add data-root and default-shm-size=$MEMORY_SIZE\"\n",
    "    sudo cp $DAEMON_PATH/daemon.json $DAEMON_PATH/daemon.json.bak\n",
    "    sudo cat $DAEMON_PATH/daemon.json.bak | jq '. += {\"data-root\":\"/home/ec2-user/SageMaker/.container/docker\",\"default-shm-size\":\"'$MEMORY_SIZE'\"}' | sudo tee $DAEMON_PATH/daemon.json > /dev/null\n",
    "    sudo service docker restart\n",
    "    echo \"Docker Restart\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e5c21c-b8d6-485e-ae1f-be715fdaa8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import IPython\n",
    "\n",
    "if install_needed:\n",
    "    print(\"installing deps and restarting kernel\")\n",
    "    !{sys.executable} -m pip install -U smdebug sagemaker-experiments\n",
    "    !{sys.executable} -m pip install -U sagemaker\n",
    "    !{sys.executable} -m pip install -U datasets transformers\n",
    "    !{sys.executable} -m pip install -U wget omegaconf text-unidecode\n",
    "    ## Install NeMo\n",
    "    BRANCH = 'main'\n",
    "    !{sys.executable} -m pip install git+https://github.com/NVIDIA/NeMo.git@$BRANCH#egg=nemo_toolkit[all]\n",
    "    !pip install --upgrade --force-reinstall llvmlite\n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac621da0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=e0043256daa791487223cd187586dd9cfe47a5d585b41edf627f6c77181d5f04\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/ba/78/fb/e0c24a9e73d7483b073d15b7e05f43f3fc2ac75eff6899c7aa\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n",
      "Loaded plugins: dkms-build-requires, extras_suggestions, langpacks, priorities,\n",
      "              : update-motd, versionlock\n",
      "amzn2-core                                               | 3.7 kB     00:00     \n",
      "amzn2extra-docker                                        | 3.0 kB     00:00     \n",
      "amzn2extra-kernel-5.10                                   | 3.0 kB     00:00     \n",
      "amzn2extra-python3.8                                     | 3.0 kB     00:00     \n",
      "centos-extras                                            | 2.9 kB     00:00     \n",
      "copr:copr.fedorainfracloud.org:vbatts:shadow-utils-newxi | 3.3 kB     00:00     \n",
      "https://download.docker.com/linux/centos/2/x86_64/stable/repodata/repomd.xml: [Errno 14] HTTPS Error 404 - Not Found\n",
      "Trying other mirror.\n",
      "libnvidia-container/x86_64/signature                     |  833 B     00:00     \n",
      "libnvidia-container/x86_64/signature                     | 2.1 kB     00:00 !!! \n",
      "neuron                                                   | 2.9 kB     00:00     \n",
      "neuron/primary_db                                          | 111 kB   00:02     \n",
      "61 packages excluded due to repository priority protections\n",
      "Resolving Dependencies\n",
      "--> Running transaction check\n",
      "---> Package sox.x86_64 0:14.4.1-7.amzn2 will be installed\n",
      "--> Processing Dependency: libpulse.so.0(PULSE_0)(64bit) for package: sox-14.4.1-7.amzn2.x86_64\n",
      "--> Processing Dependency: libpulse-simple.so.0(PULSE_0)(64bit) for package: sox-14.4.1-7.amzn2.x86_64\n",
      "--> Processing Dependency: libao.so.4(LIBAO4_1.1.0)(64bit) for package: sox-14.4.1-7.amzn2.x86_64\n",
      "--> Processing Dependency: libwavpack.so.1()(64bit) for package: sox-14.4.1-7.amzn2.x86_64\n",
      "--> Processing Dependency: libpulse.so.0()(64bit) for package: sox-14.4.1-7.amzn2.x86_64\n",
      "--> Processing Dependency: libpulse-simple.so.0()(64bit) for package: sox-14.4.1-7.amzn2.x86_64\n",
      "--> Processing Dependency: libao.so.4()(64bit) for package: sox-14.4.1-7.amzn2.x86_64\n",
      "--> Running transaction check\n",
      "---> Package libao.x86_64 0:1.1.0-8.amzn2.0.2 will be installed\n",
      "---> Package pulseaudio-libs.x86_64 0:10.0-3.amzn2.0.3 will be installed\n",
      "--> Processing Dependency: libasyncns.so.0()(64bit) for package: pulseaudio-libs-10.0-3.amzn2.0.3.x86_64\n",
      "---> Package wavpack.x86_64 0:4.60.1-9.amzn2.0.1 will be installed\n",
      "--> Running transaction check\n",
      "---> Package libasyncns.x86_64 0:0.8-7.amzn2.0.2 will be installed\n",
      "--> Finished Dependency Resolution\n",
      "\n",
      "Dependencies Resolved\n",
      "\n",
      "================================================================================\n",
      " Package              Arch        Version                 Repository       Size\n",
      "================================================================================\n",
      "Installing:\n",
      " sox                  x86_64      14.4.1-7.amzn2          amzn2-core      401 k\n",
      "Installing for dependencies:\n",
      " libao                x86_64      1.1.0-8.amzn2.0.2       amzn2-core       72 k\n",
      " libasyncns           x86_64      0.8-7.amzn2.0.2         amzn2-core       26 k\n",
      " pulseaudio-libs      x86_64      10.0-3.amzn2.0.3        amzn2-core      648 k\n",
      " wavpack              x86_64      4.60.1-9.amzn2.0.1      amzn2-core      132 k\n",
      "\n",
      "Transaction Summary\n",
      "================================================================================\n",
      "Install  1 Package (+4 Dependent packages)\n",
      "\n",
      "Total download size: 1.2 M\n",
      "Installed size: 4.8 M\n",
      "Downloading packages:\n",
      "(1/5): libasyncns-0.8-7.amzn2.0.2.x86_64.rpm               |  26 kB   00:00     \n",
      "(2/5): libao-1.1.0-8.amzn2.0.2.x86_64.rpm                  |  72 kB   00:00     \n",
      "(3/5): pulseaudio-libs-10.0-3.amzn2.0.3.x86_64.rpm         | 648 kB   00:00     \n",
      "(4/5): sox-14.4.1-7.amzn2.x86_64.rpm                       | 401 kB   00:00     \n",
      "(5/5): wavpack-4.60.1-9.amzn2.0.1.x86_64.rpm               | 132 kB   00:00     \n",
      "--------------------------------------------------------------------------------\n",
      "Total                                              2.7 MB/s | 1.2 MB  00:00     \n",
      "Running transaction check\n",
      "Running transaction test\n",
      "Transaction test succeeded\n",
      "Running transaction\n",
      "Warning: RPMDB altered outside of yum.\n",
      "  Installing : wavpack-4.60.1-9.amzn2.0.1.x86_64                            1/5 \n",
      "  Installing : libasyncns-0.8-7.amzn2.0.2.x86_64                            2/5 \n",
      "  Installing : pulseaudio-libs-10.0-3.amzn2.0.3.x86_64                      3/5 \n",
      "  Installing : libao-1.1.0-8.amzn2.0.2.x86_64                               4/5 \n",
      "  Installing : sox-14.4.1-7.amzn2.x86_64                                    5/5 \n",
      "  Verifying  : libasyncns-0.8-7.amzn2.0.2.x86_64                            1/5 \n",
      "  Verifying  : sox-14.4.1-7.amzn2.x86_64                                    2/5 \n",
      "  Verifying  : libao-1.1.0-8.amzn2.0.2.x86_64                               3/5 \n",
      "  Verifying  : pulseaudio-libs-10.0-3.amzn2.0.3.x86_64                      4/5 \n",
      "  Verifying  : wavpack-4.60.1-9.amzn2.0.1.x86_64                            5/5 \n",
      "\n",
      "Installed:\n",
      "  sox.x86_64 0:14.4.1-7.amzn2                                                   \n",
      "\n",
      "Dependency Installed:\n",
      "  libao.x86_64 0:1.1.0-8.amzn2.0.2          libasyncns.x86_64 0:0.8-7.amzn2.0.2\n",
      "  pulseaudio-libs.x86_64 0:10.0-3.amzn2.0.3 wavpack.x86_64 0:4.60.1-9.amzn2.0.1\n",
      "\n",
      "Complete!\n",
      "Loaded plugins: dkms-build-requires, extras_suggestions, langpacks, priorities,\n",
      "              : update-motd, versionlock\n",
      "Existing lock /var/run/yum.pid: another copy is running as pid 13189.\n",
      "Another app is currently holding the yum lock; waiting for it to exit...\n",
      "  The other application is: yum\n",
      "    Memory :  42 M RSS (259 MB VSZ)\n",
      "    Started: Fri Mar 10 08:04:38 2023 - 00:01 ago\n",
      "    State  : Running, pid: 13189\n",
      "amzn2-core                                               | 3.7 kB     00:00     \n",
      "amzn2extra-docker                                        | 3.0 kB     00:00     \n",
      "amzn2extra-kernel-5.10                                   | 3.0 kB     00:00     \n",
      "amzn2extra-python3.8                                     | 3.0 kB     00:00     \n",
      "centos-extras                                            | 2.9 kB     00:00     \n",
      "copr:copr.fedorainfracloud.org:vbatts:shadow-utils-newxi | 3.3 kB     00:00     \n",
      "https://download.docker.com/linux/centos/2/x86_64/stable/repodata/repomd.xml: [Errno 14] HTTPS Error 404 - Not Found\n",
      "Trying other mirror.\n",
      "libnvidia-container/x86_64/signature                     |  833 B     00:00     \n",
      "libnvidia-container/x86_64/signature                     | 2.1 kB     00:00 !!! \n",
      "neuron                                                   | 2.9 kB     00:00     \n",
      "61 packages excluded due to repository priority protections\n",
      "Package libsndfile-1.0.25-12.amzn2.1.x86_64 already installed and latest version\n",
      "Nothing to do\n",
      "--2023-03-10 08:04:47--  https://www.johnvansickle.com/ffmpeg/old-releases/ffmpeg-4.2.1-amd64-static.tar.xz\n",
      "Resolving www.johnvansickle.com (www.johnvansickle.com)... 107.180.57.212\n",
      "Connecting to www.johnvansickle.com (www.johnvansickle.com)|107.180.57.212|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 37401456 (36M) [application/x-xz]\n",
      "Saving to: ‘ffmpeg-4.2.1-amd64-static.tar.xz’\n",
      "\n",
      "100%[======================================>] 37,401,456  9.34MB/s   in 5.3s   \n",
      "\n",
      "2023-03-10 08:04:53 (6.76 MB/s) - ‘ffmpeg-4.2.1-amd64-static.tar.xz’ saved [37401456/37401456]\n",
      "\n",
      "ffmpeg-4.2.1-amd64-static/\n",
      "ffmpeg-4.2.1-amd64-static/GPLv3.txt\n",
      "ffmpeg-4.2.1-amd64-static/manpages/\n",
      "ffmpeg-4.2.1-amd64-static/manpages/ffmpeg-all.txt\n",
      "ffmpeg-4.2.1-amd64-static/manpages/ffmpeg-scaler.txt\n",
      "ffmpeg-4.2.1-amd64-static/manpages/ffmpeg-resampler.txt\n",
      "ffmpeg-4.2.1-amd64-static/manpages/ffmpeg-filters.txt\n",
      "ffmpeg-4.2.1-amd64-static/manpages/ffprobe.txt\n",
      "ffmpeg-4.2.1-amd64-static/manpages/ffmpeg-devices.txt\n",
      "ffmpeg-4.2.1-amd64-static/manpages/ffmpeg-utils.txt\n",
      "ffmpeg-4.2.1-amd64-static/manpages/ffmpeg-protocols.txt\n",
      "ffmpeg-4.2.1-amd64-static/manpages/ffmpeg-codecs.txt\n",
      "ffmpeg-4.2.1-amd64-static/manpages/ffmpeg-bitstream-filters.txt\n",
      "ffmpeg-4.2.1-amd64-static/manpages/ffmpeg.txt\n",
      "ffmpeg-4.2.1-amd64-static/manpages/ffmpeg-formats.txt\n",
      "ffmpeg-4.2.1-amd64-static/ffprobe\n",
      "ffmpeg-4.2.1-amd64-static/qt-faststart\n",
      "ffmpeg-4.2.1-amd64-static/model/\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_v0.6.1.pkl.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_v0.6.1.pkl\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0020.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0005\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0015\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0016.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0008.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0020\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0017.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0014\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0011\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0012\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0004\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0005.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0013.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0007.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0001\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0009\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0009.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0004.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0019.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0007\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0006\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0017\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0011.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0008\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0010\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0018\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0002.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0012.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0003.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0019\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0014.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0018.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0016\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0010.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0001.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0003\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0015.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0013\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0006.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0002\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0019.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0005.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0004\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0015\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0010.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0012.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0005\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0008.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0009\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0018\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0015.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0011\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0014.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0012\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0003.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0006.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0013.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0001\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0011.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0007\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0006\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0017\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0008\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0003\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0002\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0004.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0001.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0018.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0002.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0014\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0017.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0019\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0009.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0013\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0007.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0016.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0010\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0016\n",
      "ffmpeg-4.2.1-amd64-static/model/000-PLEASE-README.TXT\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0008.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0012\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0002.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0007.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0011.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0019\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0017.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0017\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0009\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0010\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0005.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0009.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0013\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0018\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0013.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0014\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0004\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0006.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0005\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0007\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0019.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0015.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0010.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0008\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0004.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0006\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0001.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0016.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0015\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0003.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0011\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0016\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0003\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0014.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0018.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0001\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0002\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0012.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0012.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0005\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0020.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0009\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0014\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0001.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0019.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0010.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0009.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0010\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0012\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0013\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0016.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0014.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0019\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0015\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0006\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0007.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0002.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0004.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0011.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0006.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0018\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0008.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0018.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0011\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0007\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0020\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0003.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0013.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0005.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0001\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0016\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0008\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0003\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0004\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0017.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0002\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0015.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0017\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/nflxall_vmafv2.pkl.model\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/vmaf_v0.6.0.pkl\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/nflx_vmaff_rf_v2.pkl\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/nflxtrain_vmafv2.pkl\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/nflxtrain_vmafv3.pkl\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/niqe_v0.1.pkl\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/nflxtrain_libsvmnusvr_currentbest.pkl.model\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/nflxall_vmafv3.pkl.model\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/nflxall_vmafv1.pkl\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/nflx_v1.pkl\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/vmaf_4k_v0.6.1rc.pkl\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/nflxall_vmafv4.pkl\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/vmaf_4k_v0.6.1rc.pkl.model\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/nflx_v1.pkl.model\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/nflxtrain_vmafv1.pkl.model\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/nflxall_vmafv4.pkl.model\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/nflxtrain_vmafv1.pkl\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/nflxall_libsvmnusvr_currentbest.pkl.model\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/nflxtrain_vmafv3a.pkl\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/nflxtrain_vmafv3.pkl.model\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/nflxtrain_norm_type_none.pkl\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/vmaf_v0.6.0.pkl.model\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/nflxall_vmafv3a.pkl\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/nflxall_vmafv1.pkl.model\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/nflxall_vmafv3.pkl\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/nflxtrain_libsvmnusvr_currentbest.pkl\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/nflxall_libsvmnusvr_currentbest.pkl\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/nflx_vmaff_rf_v1.pkl\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/nflxtrain_vmafv2.pkl.model\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/nflxall_vmafv2.pkl\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/model_V8a.model\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/nflxtrain_norm_type_none.pkl.model\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/nflxtrain_vmafv3a.pkl.model\n",
      "ffmpeg-4.2.1-amd64-static/model/other_models/nflxall_vmafv3a.pkl.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_4k_v0.6.1.pkl.model\n",
      "ffmpeg-4.2.1-amd64-static/model/vmaf_v0.6.1.pkl\n",
      "ffmpeg-4.2.1-amd64-static/readme.txt\n",
      "ffmpeg-4.2.1-amd64-static/ffmpeg\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting numba==0.53.1\n",
      "  Downloading numba-0.53.1-cp39-cp39-manylinux2014_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from numba==0.53.1) (65.6.3)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from numba==0.53.1) (1.23.5)\n",
      "Collecting llvmlite<0.37,>=0.36.0rc1\n",
      "  Downloading llvmlite-0.36.0-cp39-cp39-manylinux2010_x86_64.whl (25.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.3/25.3 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: llvmlite, numba\n",
      "  Attempting uninstall: llvmlite\n",
      "    Found existing installation: llvmlite 0.39.1\n",
      "    Uninstalling llvmlite-0.39.1:\n",
      "      Successfully uninstalled llvmlite-0.39.1\n",
      "  Attempting uninstall: numba\n",
      "    Found existing installation: numba 0.56.4\n",
      "    Uninstalling numba-0.56.4:\n",
      "      Successfully uninstalled numba-0.56.4\n",
      "Successfully installed llvmlite-0.36.0 numba-0.53.1\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: text-unidecode in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (1.3)\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: sagemaker==2.118.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (2.118.0)\n",
      "Requirement already satisfied: awscli in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (1.27.71)\n",
      "Collecting sagemaker-training\n",
      "  Downloading sagemaker_training-4.4.8.tar.gz (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker==2.118.0) (1.4.4)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker==2.118.0) (1.0.1)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker==2.118.0) (0.7.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker==2.118.0) (21.3)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker==2.118.0) (4.13.0)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker==2.118.0) (0.3.0)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker==2.118.0) (3.20.2)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker==2.118.0) (0.2.0)\n",
      "Requirement already satisfied: attrs<23,>=20.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker==2.118.0) (22.2.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.20 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker==2.118.0) (1.26.88)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker==2.118.0) (0.1.5)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker==2.118.0) (1.23.5)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from awscli) (0.6.0)\n",
      "Requirement already satisfied: PyYAML<5.5,>=3.10 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from awscli) (5.4.1)\n",
      "Requirement already satisfied: rsa<4.8,>=3.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from awscli) (4.7.2)\n",
      "Requirement already satisfied: docutils<0.17,>=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from awscli) (0.15.2)\n",
      "Collecting botocore==1.29.71\n",
      "  Using cached botocore-1.29.71-py3-none-any.whl (10.4 MB)\n",
      "Requirement already satisfied: colorama<0.4.5,>=0.2.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from awscli) (0.4.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from botocore==1.29.71->awscli) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from botocore==1.29.71->awscli) (1.26.8)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from botocore==1.29.71->awscli) (1.0.1)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker-training) (1.16.0)\n",
      "Requirement already satisfied: pip in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker-training) (22.3.1)\n",
      "Collecting retrying>=1.3.3\n",
      "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: gevent in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker-training) (22.10.2)\n",
      "Collecting inotify_simple==1.2.1\n",
      "  Downloading inotify_simple-1.2.1.tar.gz (7.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.15.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker-training) (2.2.2)\n",
      "Requirement already satisfied: paramiko>=2.4.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker-training) (3.0.0)\n",
      "Requirement already satisfied: psutil>=5.6.7 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker-training) (5.9.4)\n",
      "Requirement already satisfied: scipy>=1.2.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker-training) (1.8.1)\n",
      "Collecting boto3<2.0,>=1.26.20\n",
      "  Downloading boto3-1.26.87-py3-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.7/134.7 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading boto3-1.26.86-py3-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.7/134.7 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading boto3-1.26.85-py3-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.7/134.7 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading boto3-1.26.84-py3-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.7/134.7 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading boto3-1.26.83-py3-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.7/134.7 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading boto3-1.26.82-py3-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.7/134.7 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading boto3-1.26.81-py3-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.7/134.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading boto3-1.26.80-py3-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading boto3-1.26.79-py3-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading boto3-1.26.78-py3-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading boto3-1.26.77-py3-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading boto3-1.26.76-py3-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading boto3-1.26.75-py3-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading boto3-1.26.74-py3-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading boto3-1.26.73-py3-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading boto3-1.26.72-py3-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Using cached boto3-1.26.71-py3-none-any.whl (132 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker==2.118.0) (3.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from packaging>=20.0->sagemaker==2.118.0) (3.0.9)\n",
      "Requirement already satisfied: pynacl>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from paramiko>=2.4.2->sagemaker-training) (1.5.0)\n",
      "Requirement already satisfied: cryptography>=3.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from paramiko>=2.4.2->sagemaker-training) (39.0.0)\n",
      "Requirement already satisfied: bcrypt>=3.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from paramiko>=2.4.2->sagemaker-training) (4.0.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from rsa<4.8,>=3.1.2->awscli) (0.4.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from werkzeug>=0.15.5->sagemaker-training) (2.1.1)\n",
      "Requirement already satisfied: greenlet>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gevent->sagemaker-training) (2.0.1)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gevent->sagemaker-training) (65.6.3)\n",
      "Requirement already satisfied: zope.event in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gevent->sagemaker-training) (4.6)\n",
      "Requirement already satisfied: zope.interface in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gevent->sagemaker-training) (5.5.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pandas->sagemaker==2.118.0) (2022.7)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pathos->sagemaker==2.118.0) (0.70.14)\n",
      "Requirement already satisfied: pox>=0.3.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pathos->sagemaker==2.118.0) (0.3.2)\n",
      "Requirement already satisfied: dill>=0.3.6 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pathos->sagemaker==2.118.0) (0.3.6)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pathos->sagemaker==2.118.0) (1.7.6.6)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from schema->sagemaker==2.118.0) (21.6.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from cryptography>=3.3->paramiko>=2.4.2->sagemaker-training) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=3.3->paramiko>=2.4.2->sagemaker-training) (2.21)\n",
      "Building wheels for collected packages: sagemaker-training, inotify_simple\n",
      "  Building wheel for sagemaker-training (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker-training: filename=sagemaker_training-4.4.8-cp39-cp39-linux_x86_64.whl size=77008 sha256=6b41b2c9415cb55b48ac3229bf5d92227b54d1e89c842762eb651d3023b5ab2a\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/94/19/d6/96061cb58382daef353286217394c9438cd7b6212c5894b0e6\n",
      "  Building wheel for inotify_simple (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for inotify_simple: filename=inotify_simple-1.2.1-py3-none-any.whl size=8201 sha256=346f82709d210526c6084ef905cc8271e3c74973156908dc9c2ce1dc649fd67e\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/3f/c2/6a/6f6c65836d2fad9ae7008373d82e38b519187113fac6b720c8\n",
      "Successfully built sagemaker-training inotify_simple\n",
      "Installing collected packages: inotify_simple, retrying, botocore, boto3, sagemaker-training\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.29.88\n",
      "    Uninstalling botocore-1.29.88:\n",
      "      Successfully uninstalled botocore-1.29.88\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.26.88\n",
      "    Uninstalling boto3-1.26.88:\n",
      "      Successfully uninstalled boto3-1.26.88\n",
      "Successfully installed boto3-1.26.71 botocore-1.29.71 inotify_simple-1.2.1 retrying-1.3.4 sagemaker-training-4.4.8\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting librosa==0.9.2\n",
      "  Downloading librosa-0.9.2-py3-none-any.whl (214 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from librosa==0.9.2) (1.8.1)\n",
      "Collecting audioread>=2.1.9\n",
      "  Downloading audioread-3.0.0.tar.gz (377 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting soundfile>=0.10.2\n",
      "  Downloading soundfile-0.12.1-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: numba>=0.45.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from librosa==0.9.2) (0.53.1)\n",
      "Collecting resampy>=0.2.2\n",
      "  Downloading resampy-0.4.2-py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: decorator>=4.0.10 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from librosa==0.9.2) (5.1.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from librosa==0.9.2) (1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from librosa==0.9.2) (21.3)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from librosa==0.9.2) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from librosa==0.9.2) (1.23.5)\n",
      "Requirement already satisfied: pooch>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from librosa==0.9.2) (1.6.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from numba>=0.45.1->librosa==0.9.2) (65.6.3)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from numba>=0.45.1->librosa==0.9.2) (0.36.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from packaging>=20.0->librosa==0.9.2) (3.0.9)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pooch>=1.0->librosa==0.9.2) (2.28.1)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pooch>=1.0->librosa==0.9.2) (1.4.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from scikit-learn>=0.19.1->librosa==0.9.2) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from soundfile>=0.10.2->librosa==0.9.2) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.9.2) (2.21)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.2) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.2) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.2) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.2) (1.26.8)\n",
      "Building wheels for collected packages: audioread\n",
      "  Building wheel for audioread (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for audioread: filename=audioread-3.0.0-py3-none-any.whl size=23704 sha256=5734cbce8e95459cf38e75ab518fcda2671473452c3d3dfa6464028caecfdc83\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/7a/6a/b0/92760a6d6bc2bff5464970af910c0b0b921390993f3199cdf7\n",
      "Successfully built audioread\n",
      "Installing collected packages: audioread, soundfile, resampy, librosa\n",
      "Successfully installed audioread-3.0.0 librosa-0.9.2 resampy-0.4.2 soundfile-0.12.1\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting nemo_toolkit[all]\n",
      "  Cloning https://github.com/NVIDIA/NeMo.git (to revision main) to /tmp/pip-install-olffx0es/nemo-toolkit_0db2efbbab6349ec9f18fe93548c20d6\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/NVIDIA/NeMo.git /tmp/pip-install-olffx0es/nemo-toolkit_0db2efbbab6349ec9f18fe93548c20d6\n",
      "  Resolved https://github.com/NVIDIA/NeMo.git to commit ff501bd8e3991ca85ebd02834eadd3d1e3198f42\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: ruamel.yaml in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nemo_toolkit[all]) (0.17.21)\n",
      "Collecting setuptools==59.5.0\n",
      "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m952.4/952.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nemo_toolkit[all]) (1.23.5)\n",
      "Collecting huggingface-hub\n",
      "  Downloading huggingface_hub-0.13.1-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard\n",
      "  Downloading tensorboard-2.12.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nemo_toolkit[all]) (1.13.1)\n",
      "Requirement already satisfied: wrapt in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nemo_toolkit[all]) (1.14.1)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nemo_toolkit[all]) (4.63.2)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nemo_toolkit[all]) (1.0)\n",
      "Requirement already satisfied: text-unidecode in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nemo_toolkit[all]) (1.3)\n",
      "Requirement already satisfied: wget in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nemo_toolkit[all]) (3.2)\n",
      "Requirement already satisfied: python-dateutil in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nemo_toolkit[all]) (2.8.2)\n",
      "Requirement already satisfied: numba in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nemo_toolkit[all]) (0.53.1)\n",
      "Requirement already satisfied: onnx>=1.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nemo_toolkit[all]) (1.11.0)\n",
      "Requirement already satisfied: nltk in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nemo_toolkit[all]) (3.8.1)\n",
      "Collecting rapidfuzz\n",
      "  Downloading rapidfuzz-2.13.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting black==19.10b0\n",
      "  Downloading black-19.10b0-py36-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.5/97.5 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting attrdict\n",
      "  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nemo_toolkit[all]) (1.8.1)\n",
      "Requirement already satisfied: flask-restful in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nemo_toolkit[all]) (0.3.9)\n",
      "Collecting nemo-text-processing==0.1.6rc0\n",
      "  Downloading nemo_text_processing-0.1.6rc0-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m143.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pypinyin\n",
      "  Downloading pypinyin-0.48.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pypinyin-dict\n",
      "  Downloading pypinyin_dict-0.5.0-py2.py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m141.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jiwer\n",
      "  Downloading jiwer-2.5.1-py3-none-any.whl (15 kB)\n",
      "Collecting kaldi-python-io\n",
      "  Downloading kaldi-python-io-1.2.2.tar.gz (8.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nemo_toolkit[all]) (1.4.4)\n",
      "Collecting inflect\n",
      "  Downloading inflect-6.0.2-py3-none-any.whl (34 kB)\n",
      "Collecting pyannote.core\n",
      "  Downloading pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting webdataset<=0.1.62,>=0.1.48\n",
      "  Downloading webdataset-0.1.62-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: soundfile in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nemo_toolkit[all]) (0.12.1)\n",
      "Collecting sox\n",
      "  Downloading sox-1.4.1-py2.py3-none-any.whl (39 kB)\n",
      "Collecting kaldiio\n",
      "  Downloading kaldiio-2.17.2.tar.gz (24 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting youtokentome>=1.0.5\n",
      "  Downloading youtokentome-1.0.6.tar.gz (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: isort<6.0.0,>5.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nemo_toolkit[all]) (5.11.4)\n",
      "Collecting omegaconf<2.3,>=2.2\n",
      "  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nemo_toolkit[all]) (3.7.0)\n",
      "Collecting gradio\n",
      "  Downloading gradio-3.20.1-py3-none-any.whl (14.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pytest-runner\n",
      "  Using cached pytest_runner-6.0.0-py3-none-any.whl (7.2 kB)\n",
      "Collecting sphinxcontrib-bibtex\n",
      "  Downloading sphinxcontrib_bibtex-2.5.0-py3-none-any.whl (39 kB)\n",
      "Collecting ijson\n",
      "  Downloading ijson-3.2.0.post0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (112 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting click==8.0.2\n",
      "  Downloading click-8.0.2-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: librosa in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nemo_toolkit[all]) (0.9.2)\n",
      "Collecting sacrebleu[ja]\n",
      "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting editdistance\n",
      "  Downloading editdistance-0.6.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.4/282.4 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wandb\n",
      "  Downloading wandb-0.13.11-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting gdown\n",
      "  Downloading gdown-4.6.4-py3-none-any.whl (14 kB)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sacremoses>=0.0.43\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting progress>=1.5\n",
      "  Downloading progress-1.6.tar.gz (7.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nemo_toolkit[all]) (3.5.3)\n",
      "Collecting texterrors\n",
      "  Downloading texterrors-0.4.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml<6 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nemo_toolkit[all]) (5.4.1)\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nemo_toolkit[all]) (1.26.71)\n",
      "Collecting parameterized\n",
      "  Downloading parameterized-0.8.1-py2.py3-none-any.whl (26 kB)\n",
      "Collecting opencc\n",
      "  Downloading OpenCC-1.1.6-cp39-cp39-manylinux1_x86_64.whl (778 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m778.3/778.3 kB\u001b[0m \u001b[31m108.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytest in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nemo_toolkit[all]) (7.2.0)\n",
      "Collecting g2p-en\n",
      "  Downloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m140.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fasttext\n",
      "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: textdistance>=4.1.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nemo_toolkit[all]) (4.5.0)\n",
      "Requirement already satisfied: tabulate>=0.8.7 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nemo_toolkit[all]) (0.9.0)\n",
      "Collecting torchmetrics>=0.11.0\n",
      "  Downloading torchmetrics-0.11.3-py3-none-any.whl (518 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m518.6/518.6 kB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sphinx in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nemo_toolkit[all]) (5.1.1)\n",
      "Collecting sentencepiece<1.0.0\n",
      "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m118.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyannote.metrics\n",
      "  Downloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jieba\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting braceexpand\n",
      "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nemo_toolkit[all]) (21.3)\n",
      "Collecting pangu\n",
      "  Downloading pangu-4.0.6.1-py3-none-any.whl (6.4 kB)\n",
      "Collecting transformers>=4.0.1\n",
      "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pytorch-lightning>=1.9.0\n",
      "  Downloading pytorch_lightning-1.9.4-py3-none-any.whl (827 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m827.8/827.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: ipywidgets in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nemo_toolkit[all]) (8.0.4)\n",
      "Collecting hydra-core<1.3,>=1.2.0\n",
      "  Downloading hydra_core-1.2.0-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.1/151.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.7.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting kornia\n",
      "  Downloading kornia-0.6.10-py2.py3-none-any.whl (612 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.0/612.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting marshmallow\n",
      "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting einops\n",
      "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ftfy\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typed-ast>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from black==19.10b0->nemo_toolkit[all]) (1.5.4)\n",
      "Requirement already satisfied: appdirs in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from black==19.10b0->nemo_toolkit[all]) (1.4.4)\n",
      "Requirement already satisfied: pathspec<1,>=0.6 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from black==19.10b0->nemo_toolkit[all]) (0.10.3)\n",
      "Requirement already satisfied: regex in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from black==19.10b0->nemo_toolkit[all]) (2022.10.31)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from black==19.10b0->nemo_toolkit[all]) (22.2.0)\n",
      "Requirement already satisfied: toml>=0.9.4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from black==19.10b0->nemo_toolkit[all]) (0.10.2)\n",
      "Collecting cdifflib\n",
      "  Downloading cdifflib-1.2.6.tar.gz (11 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nemo-text-processing==0.1.6rc0->nemo_toolkit[all]) (1.2.0)\n",
      "Collecting pynini\n",
      "  Downloading pynini-2.1.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.3/161.3 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Cython>=0.29 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pynini->nemo-text-processing==0.1.6rc0->nemo_toolkit[all]) (0.29.33)\n",
      "Collecting antlr4-python3-runtime==4.9.*\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting levenshtein==0.20.2\n",
      "  Downloading Levenshtein-0.20.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: resampy>=0.2.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from librosa->nemo_toolkit[all]) (0.4.2)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from librosa->nemo_toolkit[all]) (3.0.0)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from librosa->nemo_toolkit[all]) (5.1.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from librosa->nemo_toolkit[all]) (1.6.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from matplotlib>=3.3.2->nemo_toolkit[all]) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from matplotlib>=3.3.2->nemo_toolkit[all]) (4.38.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from matplotlib>=3.3.2->nemo_toolkit[all]) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from matplotlib>=3.3.2->nemo_toolkit[all]) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from matplotlib>=3.3.2->nemo_toolkit[all]) (9.2.0)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from numba->nemo_toolkit[all]) (0.36.0)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from onnx>=1.7.0->nemo_toolkit[all]) (3.20.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from onnx>=1.7.0->nemo_toolkit[all]) (4.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from python-dateutil->nemo_toolkit[all]) (1.16.0)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pytorch-lightning>=1.9.0->nemo_toolkit[all]) (2022.11.0)\n",
      "Collecting lightning-utilities>=0.6.0.post0\n",
      "  Downloading lightning_utilities-0.7.1-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from scikit-learn->nemo_toolkit[all]) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from soundfile->nemo_toolkit[all]) (1.15.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers>=4.0.1->nemo_toolkit[all]) (2.28.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers>=4.0.1->nemo_toolkit[all]) (3.6.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from boto3->nemo_toolkit[all]) (0.6.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from boto3->nemo_toolkit[all]) (1.0.1)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.71 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from boto3->nemo_toolkit[all]) (1.29.71)\n",
      "Requirement already satisfied: pybind11>=2.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from fasttext->nemo_toolkit[all]) (2.9.2)\n",
      "Requirement already satisfied: Flask>=0.8 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from flask-restful->nemo_toolkit[all]) (2.2.2)\n",
      "Requirement already satisfied: aniso8601>=0.82 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from flask-restful->nemo_toolkit[all]) (9.0.1)\n",
      "Requirement already satisfied: pytz in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from flask-restful->nemo_toolkit[all]) (2022.7)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ftfy->nemo_toolkit[all]) (0.2.5)\n",
      "Collecting distance>=0.1.3\n",
      "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pydantic>=1.9.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from inflect->nemo_toolkit[all]) (1.10.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gdown->nemo_toolkit[all]) (4.11.1)\n",
      "Collecting altair>=4.2.0\n",
      "  Downloading altair-4.2.2-py3-none-any.whl (813 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m813.6/813.6 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting markdown-it-py[linkify]>=2.0.0\n",
      "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiofiles\n",
      "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting orjson\n",
      "  Downloading orjson-3.8.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (271 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.4/271.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting uvicorn\n",
      "  Downloading uvicorn-0.21.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httpx\n",
      "  Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-multipart\n",
      "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pycryptodome in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->nemo_toolkit[all]) (3.16.0)\n",
      "Collecting fastapi\n",
      "  Downloading fastapi-0.93.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m703.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: markupsafe in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->nemo_toolkit[all]) (2.1.1)\n",
      "Collecting websockets>=10.0\n",
      "  Downloading websockets-10.4-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mdit-py-plugins<=0.3.3\n",
      "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ffmpy\n",
      "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->nemo_toolkit[all]) (3.8.3)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->nemo_toolkit[all]) (3.1.2)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ipywidgets->nemo_toolkit[all]) (6.20.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ipywidgets->nemo_toolkit[all]) (4.0.5)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ipywidgets->nemo_toolkit[all]) (3.0.5)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ipywidgets->nemo_toolkit[all]) (5.8.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ipywidgets->nemo_toolkit[all]) (7.32.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pyannote.core->nemo_toolkit[all]) (2.4.0)\n",
      "Requirement already satisfied: sympy>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pyannote.metrics->nemo_toolkit[all]) (1.11.1)\n",
      "Collecting pyannote.database>=4.0.1\n",
      "  Downloading pyannote.database-4.1.3-py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: docopt>=0.6.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pyannote.metrics->nemo_toolkit[all]) (0.6.2)\n",
      "Requirement already satisfied: iniconfig in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pytest->nemo_toolkit[all]) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pytest->nemo_toolkit[all]) (1.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pytest->nemo_toolkit[all]) (1.1.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pytest->nemo_toolkit[all]) (2.0.1)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ruamel.yaml->nemo_toolkit[all]) (0.2.7)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (7.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: colorama in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sacrebleu[ja]->nemo_toolkit[all]) (0.4.3)\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting mecab-python3==1.0.5\n",
      "  Downloading mecab_python3-1.0.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (581 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.0/581.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting ipadic<2.0,>=1.0\n",
      "  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sentence-transformers->nemo_toolkit[all]) (0.14.1)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sphinx->nemo_toolkit[all]) (0.7.12)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sphinx->nemo_toolkit[all]) (4.13.0)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sphinx->nemo_toolkit[all]) (2.2.0)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sphinx->nemo_toolkit[all]) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sphinx->nemo_toolkit[all]) (2.0.0)\n",
      "Requirement already satisfied: babel>=1.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sphinx->nemo_toolkit[all]) (2.11.0)\n",
      "Requirement already satisfied: docutils<0.20,>=0.14 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sphinx->nemo_toolkit[all]) (0.15.2)\n",
      "Requirement already satisfied: imagesize in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sphinx->nemo_toolkit[all]) (1.4.1)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sphinx->nemo_toolkit[all]) (1.1.5)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sphinx->nemo_toolkit[all]) (1.0.3)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sphinx->nemo_toolkit[all]) (1.0.2)\n",
      "Requirement already satisfied: Pygments>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sphinx->nemo_toolkit[all]) (2.14.0)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sphinx->nemo_toolkit[all]) (1.0.1)\n",
      "Collecting pybtex>=0.24\n",
      "  Downloading pybtex-0.24.0-py2.py3-none-any.whl (561 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.4/561.4 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pybtex-docutils>=1.0.0\n",
      "  Downloading pybtex_docutils-1.0.2-py3-none-any.whl (6.3 kB)\n",
      "Collecting grpcio>=1.48.2\n",
      "  Downloading grpcio-1.51.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m135.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorboard->nemo_toolkit[all]) (2.2.2)\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.16.2-py2.py3-none-any.whl (177 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.2/177.2 kB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorboard->nemo_toolkit[all]) (0.38.4)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: termcolor in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from texterrors->nemo_toolkit[all]) (2.2.0)\n",
      "Collecting loguru\n",
      "  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting plac\n",
      "  Downloading plac-1.3.5-py2.py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from wandb->nemo_toolkit[all]) (5.9.4)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting setproctitle\n",
      "  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0\n",
      "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.16.0-py2.py3-none-any.whl (184 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: entrypoints in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from altair>=4.2.0->gradio->nemo_toolkit[all]) (0.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from altair>=4.2.0->gradio->nemo_toolkit[all]) (3.2.0)\n",
      "Requirement already satisfied: toolz in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from altair>=4.2.0->gradio->nemo_toolkit[all]) (0.12.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from botocore<1.30.0,>=1.29.71->boto3->nemo_toolkit[all]) (1.26.8)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from cffi>=1.0->soundfile->nemo_toolkit[all]) (2.21)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from Flask>=0.8->flask-restful->nemo_toolkit[all]) (2.1.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->gradio->nemo_toolkit[all]) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->gradio->nemo_toolkit[all]) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->gradio->nemo_toolkit[all]) (2.1.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->gradio->nemo_toolkit[all]) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->gradio->nemo_toolkit[all]) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->gradio->nemo_toolkit[all]) (4.0.2)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->nemo_toolkit[all]) (4.7.2)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from importlib-metadata>=4.4->sphinx->nemo_toolkit[all]) (3.11.0)\n",
      "Requirement already satisfied: nest-asyncio in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets->nemo_toolkit[all]) (1.5.5)\n",
      "Requirement already satisfied: comm>=0.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets->nemo_toolkit[all]) (0.1.2)\n",
      "Requirement already satisfied: debugpy>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets->nemo_toolkit[all]) (1.6.5)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets->nemo_toolkit[all]) (0.1.6)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets->nemo_toolkit[all]) (6.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets->nemo_toolkit[all]) (7.4.8)\n",
      "Requirement already satisfied: pyzmq>=17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets->nemo_toolkit[all]) (24.0.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets->nemo_toolkit[all]) (3.0.36)\n",
      "Requirement already satisfied: backcall in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets->nemo_toolkit[all]) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets->nemo_toolkit[all]) (0.18.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets->nemo_toolkit[all]) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets->nemo_toolkit[all]) (0.7.5)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting linkify-it-py<3,>=1\n",
      "  Downloading linkify_it_py-2.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: typer[all]>=0.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[all]) (0.4.2)\n",
      "Collecting latexcodec>=1.0.4\n",
      "  Downloading latexcodec-2.0.1-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->transformers>=4.0.1->nemo_toolkit[all]) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->transformers>=4.0.1->nemo_toolkit[all]) (2022.12.7)\n",
      "Collecting urllib3<1.27,>=1.25.4\n",
      "  Using cached urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sympy>=1.1->pyannote.metrics->nemo_toolkit[all]) (1.2.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from beautifulsoup4->gdown->nemo_toolkit[all]) (2.3.2.post1)\n",
      "Collecting starlette<0.26.0,>=0.25.0\n",
      "  Downloading starlette-0.25.0-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sniffio in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from httpx->gradio->nemo_toolkit[all]) (1.3.0)\n",
      "Collecting rfc3986[idna2008]<2,>=1.3\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting httpcore<0.17.0,>=0.15.0\n",
      "  Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->transformers>=4.0.1->nemo_toolkit[all]) (1.7.1)\n",
      "Collecting h11>=0.8\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
      "  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from httpcore<0.17.0,>=0.15.0->httpx->gradio->nemo_toolkit[all]) (3.6.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->nemo_toolkit[all]) (0.8.3)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio->nemo_toolkit[all]) (0.19.3)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->nemo_toolkit[all]) (5.1.3)\n",
      "Collecting uc-micro-py\n",
      "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->nemo_toolkit[all]) (0.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->nemo_toolkit[all]) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: shellingham<2.0.0,>=1.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from typer[all]>=0.2.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[all]) (1.5.0.post1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->nemo_toolkit[all]) (2.6.2)\n",
      "Building wheels for collected packages: antlr4-python3-runtime, progress, sacremoses, youtokentome, fasttext, jieba, kaldi-python-io, kaldiio, nemo_toolkit, sentence-transformers, distance, ipadic, cdifflib, ffmpy, pathtools\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=4a1ceba618b1d07a26db23d916bbacf469e30fd0cc503698f55a97a06e33c8d3\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/a7/72/3e/7d4bb4df2f34e8a15d0d764bb98e7ca19a765483710646a8b3\n",
      "  Building wheel for progress (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for progress: filename=progress-1.6-py3-none-any.whl size=9611 sha256=93de094120a27d61119aaad2938de3e2f6587ca5d5d0fa696bd6be913e00deaf\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/75/d9/93/1e85a94fd6347c86dd3e46b5f59669f30e2e8cbd4f963849a3\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=90886cdb209664d89cbcb15a501e1c5283b0e4e3e2848fbec82feedb209d2fb0\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/42/79/78/5ad3b042cb2d97c294535162cdbaf9b167e3b186eae55ab72d\n",
      "  Building wheel for youtokentome (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for youtokentome: filename=youtokentome-1.0.6-cp39-cp39-linux_x86_64.whl size=161353 sha256=9d296c43b85aa9ae79c5e274220ed94583309c5582705ee3eb91a53e91a6ab3b\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/dd/f1/44/9f0f3ec689dd3982ec158a528574ed27b2ae0df751b84479ed\n",
      "  Building wheel for fasttext (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fasttext: filename=fasttext-0.9.2-cp39-cp39-linux_x86_64.whl size=287117 sha256=f0ee3c3f0b685ffdb773dd5bb765a94ac033fd46e728ef278ef64cece386abcc\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/3f/84/86/c63cf501c46fb575152daee4b937075a5e9b31765c0e620fd4\n",
      "  Building wheel for jieba (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314458 sha256=a6bd5052c68959636f8271a21d8b4a5ee5b9af6920f0ce7ea06d92ec6af11c22\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/eb/93/ea/6588214b848a0b4356552634d02bd986ac1d1a7982d192e926\n",
      "  Building wheel for kaldi-python-io (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaldi-python-io: filename=kaldi_python_io-1.2.2-py3-none-any.whl size=8953 sha256=e152acf53fd06035ad42fb482f561124131ac61ed54ea09590afb197aa200d9f\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/18/0d/0b/3510c901a7c4f701e7949674b3bbd75b37ce37b431de642a51\n",
      "  Building wheel for kaldiio (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaldiio: filename=kaldiio-2.17.2-py3-none-any.whl size=24447 sha256=de78f4cfd300f5f87a0a8e0d4ad98d7e2ddad6ea92009661d650bc294587a2b7\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/55/ff/8d/d9205dc58594814251174a6b2afe811e652cec9611669b13e0\n",
      "  Building wheel for nemo_toolkit (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nemo_toolkit: filename=nemo_toolkit-1.17.0rc0-py3-none-any.whl size=2237746 sha256=8ba69649ff1489f00f16a32f0c377cfd5dbfa71922186bf7f4d7e8a358731b49\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-pqwimukz/wheels/af/9d/ef/62d10ba057609b5d066b4fd01b97b207270610f648fc0e1812\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125925 sha256=0826141fc0e02d49312f7df0470dc3777caebd652f01b653436a606046430948\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/4b/68/65/aba8be86302d9988b832f5e1f3417a87e4a868d396e4329f0a\n",
      "  Building wheel for distance (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16257 sha256=0646b6dc21dc94527822e28a16e35a96776cb99738252823aa872b19b7a58879\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/2a/c0/ea/da30cd372004d7c92903fe86dca15ea20770b200d797cc38d6\n",
      "  Building wheel for ipadic (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556703 sha256=aeda1c9890da294f8fa26b18604aeaf7f8d26f5d218f48f8cdf4a6ccdd970b07\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/4a/fb/28/21aa4bc5d871bbe3797f8372833fe4c589e1984c7bda05db16\n",
      "  Building wheel for cdifflib (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cdifflib: filename=cdifflib-1.2.6-cp39-cp39-linux_x86_64.whl size=12286 sha256=916d8eff3550fd8b094b4c388c1e9070b851e0b380dca41a5ce5e7b67f8ac35f\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/fc/ed/be/80c6ee2480adff091a76047e64b9bd67b6eaabd08c03e5e065\n",
      "  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4693 sha256=903807312febef4be29837d2c95bbac26d45c4cfd66d5f0d5a7f466c20504445\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/8d/02/a5/43ebb208903df15c239ac247db73fa9483efb792f74a0e445a\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=cefc168ec43054199b1cd608cd7cd9e6323286968504bd798ebc94428efae5ff\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/20/7c/09/4ad42725a29fce4bc21137c7f25f062b3655a4aea5b0e8d9a2\n",
      "Successfully built antlr4-python3-runtime progress sacremoses youtokentome fasttext jieba kaldi-python-io kaldiio nemo_toolkit sentence-transformers distance ipadic cdifflib ffmpy pathtools\n",
      "Installing collected packages: tokenizers, tensorboard-plugin-wit, sentencepiece, rfc3986, pydub, progress, plac, pathtools, parameterized, pangu, opencc, mecab-python3, jieba, ipadic, ijson, ffmpy, faiss-cpu, distance, braceexpand, antlr4-python3-runtime, websockets, webdataset, urllib3, uc-micro-py, tensorboard-data-server, sox, smmap, setuptools, setproctitle, rapidfuzz, python-multipart, pytest-runner, pypinyin, pynini, pyasn1-modules, portalocker, orjson, omegaconf, oauthlib, mdurl, lxml, loguru, latexcodec, kaldiio, kaldi-python-io, h11, grpcio, ftfy, einops, editdistance, docker-pycreds, click, cdifflib, cachetools, attrdict, aiofiles, absl-py, youtokentome, uvicorn, torchmetrics, starlette, sentry-sdk, sacremoses, sacrebleu, pypinyin-dict, pybtex, pyannote.core, marshmallow, markdown-it-py, markdown, linkify-it-py, lightning-utilities, levenshtein, kornia, inflect, hydra-core, httpcore, google-auth, gitdb, fasttext, black, texterrors, requests-oauthlib, pybtex-docutils, mdit-py-plugins, jiwer, huggingface-hub, httpx, GitPython, g2p-en, fastapi, altair, wandb, transformers, sphinxcontrib-bibtex, pytorch-lightning, pyannote.database, gradio, google-auth-oauthlib, gdown, tensorboard, sentence-transformers, pyannote.metrics, nemo-text-processing, nemo_toolkit\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.8\n",
      "    Uninstalling urllib3-1.26.8:\n",
      "      Successfully uninstalled urllib3-1.26.8\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 65.6.3\n",
      "    Uninstalling setuptools-65.6.3:\n",
      "      Successfully uninstalled setuptools-65.6.3\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.1.3\n",
      "    Uninstalling click-8.1.3:\n",
      "      Successfully uninstalled click-8.1.3\n",
      "  Attempting uninstall: black\n",
      "    Found existing installation: black 22.10.0\n",
      "    Uninstalling black-22.10.0:\n",
      "      Successfully uninstalled black-22.10.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "python-lsp-black 1.2.1 requires black>=22.3.0, but you have black 19.10b0 which is incompatible.\n",
      "jupyterlab-server 2.18.0 requires jsonschema>=4.17.3, but you have jsonschema 3.2.0 which is incompatible.\n",
      "distributed 2022.11.0 requires tornado<6.2,>=6.0.3, but you have tornado 6.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed GitPython-3.1.31 absl-py-1.4.0 aiofiles-23.1.0 altair-4.2.2 antlr4-python3-runtime-4.9.3 attrdict-2.0.1 black-19.10b0 braceexpand-0.1.7 cachetools-5.3.0 cdifflib-1.2.6 click-8.0.2 distance-0.1.3 docker-pycreds-0.4.0 editdistance-0.6.2 einops-0.6.0 faiss-cpu-1.7.3 fastapi-0.93.0 fasttext-0.9.2 ffmpy-0.3.0 ftfy-6.1.1 g2p-en-2.1.0 gdown-4.6.4 gitdb-4.0.10 google-auth-2.16.2 google-auth-oauthlib-0.4.6 gradio-3.20.1 grpcio-1.51.3 h11-0.14.0 httpcore-0.16.3 httpx-0.23.3 huggingface-hub-0.13.1 hydra-core-1.2.0 ijson-3.2.0.post0 inflect-6.0.2 ipadic-1.0.0 jieba-0.42.1 jiwer-2.5.1 kaldi-python-io-1.2.2 kaldiio-2.17.2 kornia-0.6.10 latexcodec-2.0.1 levenshtein-0.20.2 lightning-utilities-0.7.1 linkify-it-py-2.0.0 loguru-0.6.0 lxml-4.9.2 markdown-3.4.1 markdown-it-py-2.2.0 marshmallow-3.19.0 mdit-py-plugins-0.3.3 mdurl-0.1.2 mecab-python3-1.0.5 nemo-text-processing-0.1.6rc0 nemo_toolkit-1.17.0rc0 oauthlib-3.2.2 omegaconf-2.2.3 opencc-1.1.6 orjson-3.8.7 pangu-4.0.6.1 parameterized-0.8.1 pathtools-0.1.2 plac-1.3.5 portalocker-2.7.0 progress-1.6 pyannote.core-5.0.0 pyannote.database-4.1.3 pyannote.metrics-3.2.1 pyasn1-modules-0.2.8 pybtex-0.24.0 pybtex-docutils-1.0.2 pydub-0.25.1 pynini-2.1.5 pypinyin-0.48.0 pypinyin-dict-0.5.0 pytest-runner-6.0.0 python-multipart-0.0.6 pytorch-lightning-1.9.4 rapidfuzz-2.13.7 requests-oauthlib-1.3.1 rfc3986-1.5.0 sacrebleu-2.3.1 sacremoses-0.0.53 sentence-transformers-2.2.2 sentencepiece-0.1.97 sentry-sdk-1.16.0 setproctitle-1.3.2 setuptools-59.5.0 smmap-5.0.0 sox-1.4.1 sphinxcontrib-bibtex-2.5.0 starlette-0.25.0 tensorboard-2.12.0 tensorboard-data-server-0.7.0 tensorboard-plugin-wit-1.8.1 texterrors-0.4.4 tokenizers-0.13.2 torchmetrics-0.11.3 transformers-4.26.1 uc-micro-py-1.0.1 urllib3-1.26.14 uvicorn-0.21.0 wandb-0.13.11 webdataset-0.1.62 websockets-10.4 youtokentome-1.0.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nRemember to restart the runtime for the kernel to pick up any upgraded packages (e.g. matplotlib)!\\nAlternatively, you can uncomment the exit() below to crash and restart the kernel, in the case\\nthat you want to use the \"Run All Cells\" (or similar) option.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"\"\"\n",
    "# You can run either this notebook locally (if you have all the dependencies and a GPU) or on Google Colab.\n",
    "\n",
    "# Instructions for setting up Colab are as follows:\n",
    "# 1. Open a new Python 3 notebook.\n",
    "# 2. Import this notebook from GitHub (File -> Upload Notebook -> \"GITHUB\" tab -> copy/paste GitHub URL)\n",
    "# 3. Connect to an instance with a GPU (Runtime -> Change runtime type -> select \"GPU\" for hardware accelerator)\n",
    "# 4. Run this cell to set up dependencies.\n",
    "# 5. Restart the runtime (Runtime -> Restart Runtime) for any upgraded packages to take effect\n",
    "# \"\"\"\n",
    "# # If you're using Google Colab and not running locally, run this cell.\n",
    "\n",
    "# ## Install dependencies\n",
    "# !pip install wget\n",
    "# !sudo yum install sox -y\n",
    "# !sudo yum install libsndfile\n",
    "# !sudo sh ./packages/ffmpeg/install-ffmpeg-amazon-linux.sh\n",
    "# !pip install numba==0.53.1\n",
    "# !pip install text-unidecode\n",
    "# !pip install matplotlib>=3.3.2\n",
    "# !pip install sagemaker==2.118.0 awscli sagemaker-training\n",
    "# !pip install librosa==0.9.2\n",
    "\n",
    "# BRANCH = 'main'\n",
    "# !python -m pip install git+https://github.com/NVIDIA/NeMo.git@$BRANCH#egg=nemo_toolkit[all]\n",
    "\n",
    "# \"\"\"\n",
    "# Remember to restart the runtime for the kernel to pick up any upgraded packages (e.g. matplotlib)!\n",
    "# Alternatively, you can uncomment the exit() below to crash and restart the kernel, in the case\n",
    "# that you want to use the \"Run All Cells\" (or similar) option.\n",
    "# \"\"\"\n",
    "# # exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876f553d",
   "metadata": {},
   "source": [
    "### 1. Setup SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3d99a90-82d4-4864-8245-1fb283bd83e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext tensorboard\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "06901535-0c58-481d-a86e-05829ca6f50a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.6 ms, sys: 0 ns, total: 46.6 ms\n",
      "Wall time: 85.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "\n",
    "from time import strftime\n",
    "from pathlib import Path\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "sm_boto_client = boto3.client(\"sagemaker\")\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "region_name = sagemaker_session.boto_region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "862b910a-d091-4021-8fc7-88262fc78227",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.136.0\n"
     ]
    }
   ],
   "source": [
    "print(sagemaker.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9b7e09-1f12-4803-b6af-79ce9c28e7df",
   "metadata": {},
   "source": [
    "## Set Up SageMaker Experiment\n",
    "Create or load [SageMaker Experiment](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html) for the example training job. This will create an experiment trial object in SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "89485c48-a7b8-40bb-844b-cbccd61769e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_experiment(experiment_name):\n",
    "    try:\n",
    "        sm_experiment = Experiment.load(experiment_name)\n",
    "    except:\n",
    "        sm_experiment = Experiment.create(experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4fc2ec43-07f8-4165-b1e2-195a73d8a6f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_trial(experiment_name):\n",
    "    create_date = strftime(\"%m%d-%H%M%s\")\n",
    "    sm_trial = Trial.create(trial_name=f'{experiment_name}-{create_date}',\n",
    "                            experiment_name=experiment_name)\n",
    "\n",
    "    job_name = f'{sm_trial.trial_name}'\n",
    "    return job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d099a96",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Download the NeMo source code\n",
    "\n",
    "SageMaker allows you to pass in your own source code, with an entrypoint script.\n",
    "\n",
    "Below we download the AWS NeMo `config.yaml` which contains our configuration, and the `speech_to_text_ctc.py` script to run training.\n",
    "\n",
    "Our folder structure will look like this:\n",
    "\n",
    "    code/\n",
    "        speech_to_text_ctc.py\n",
    "        conf/\n",
    "            config.yaml\n",
    "    data/\n",
    "        an4/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b0c8fe4c-6f5a-44f7-a2f9-e4e24cce78f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# root_dir = Path('./an4_nemo_sagemaker/')\n",
    "# code_dir = root_dir / 'code/'\n",
    "# config_dir = code_dir / 'conf/'\n",
    "# data_dir = root_dir / 'data/'\n",
    "\n",
    "# root_dir.mkdir(exist_ok=True)\n",
    "# code_dir.mkdir(exist_ok=True)\n",
    "# config_dir.mkdir(exist_ok=True)\n",
    "# data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# config_path = str(config_dir / \"config.yaml\")\n",
    "# # wget.download(\"https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/asr/conf/conformer/conformer_ctc_char.yaml\", config_path)\n",
    "# # wget.download(\"https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/asr/asr_ctc/speech_to_text_ctc.py\", str(code_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bc7f51",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 2.1 Initialize SageMaker within Training Script\n",
    "\n",
    "We provide a helper function that we require to be imported and run at the top of the training script.\n",
    "\n",
    "This installs and setups DDP for you. It also alleviates having to import a custom container, and can leverage all of the SageMaker containers. Rather than running this cell, you could also manually do this in your script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa2199e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Setup the AN4 Dataset, upload data to S3\n",
    "\n",
    "We now download our training and validation data, uploading to S3 so that SageMaker can mount our data to the instance at runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "511832f1-e283-41fa-8687-18d0769d7fd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'nemo-test'\n",
    "code_location = f's3://{bucket}/{prefix}/backup_codes'\n",
    "output_path = f's3://{bucket}/{prefix}/model_output' \n",
    "s3_log_path = f's3://{bucket}/{prefix}/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "25c1b6e1-237a-40c1-9fe9-eb25b92a1fe0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/2023/training-code/Nvidia-NeMo/nemo-on-sagemaker/NeMo-test/dataset/'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = os.getcwd() + \"/dataset/\"\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e1c5a60a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "Dataset downloaded at: /home/ec2-user/SageMaker/2023/training-code/Nvidia-NeMo/nemo-on-sagemaker/NeMo-test/dataset//an4_sphere.tar.gz\n",
      "Converting .sph to .wav...\n",
      "Finished conversion.\n",
      "******\n",
      "******\n",
      "Training manifest created.\n",
      "Test manifest created.\n",
      "***Done***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-322537213286/an4'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    from nemo.utils.notebook_utils import download_an4\n",
    "    download_an4(\n",
    "        data_dir=str(data_dir),\n",
    "        train_mount_dir=\"/opt/ml/input/data/training/\",\n",
    "        test_mount_dir=\"/opt/ml/input/data/testing/\",\n",
    "    )\n",
    "\n",
    "    # Upload to the default bucket\n",
    "    prefix = \"an4\"\n",
    "    loc = sagemaker_session.upload_data(path=str(data_dir), bucket=bucket, key_prefix=prefix)\n",
    "else:\n",
    "    loc = f\"s3://{bucket}/{prefix}\"\n",
    "loc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6321e3a9",
   "metadata": {},
   "source": [
    "### 4. Configure the training job\n",
    "\n",
    "Now we configure the training job, by modifying the `config.yaml` file that is stored in our source code directory.\n",
    "We pass relative directory paths for the data based on the SageMaker mount directory on the remote instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4bb61640",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_path = \"an4_nemo_sagemaker/code/conf/config.yaml\"\n",
    "conf = OmegaConf.load(config_path)\n",
    "\n",
    "# Set Data Locations based on the mounted directory in the SageMaker instance\n",
    "conf.model.train_ds.manifest_filepath = \"/opt/ml/input/data/training/an4/train_manifest.json\"\n",
    "conf.model.validation_ds.manifest_filepath = \"/opt/ml/input/data/testing/an4/test_manifest.json\"\n",
    "conf.trainer.accelerator = \"gpu\"\n",
    "conf.trainer.max_epochs = 5 # 150\n",
    "\n",
    "# Output directory for our experiment within the SageMaker instance\n",
    "conf.exp_manager.exp_dir=\"/opt/ml/model/\"\n",
    "\n",
    "# Create a Small Variant of the Conformer Model\n",
    "conf.model.encoder.n_layers = 8\n",
    "conf.model.n_heads = 4\n",
    "conf.model.spec_augment.time_masks = 5\n",
    "\n",
    "# Set Optimizer parameters\n",
    "conf.model.optim.lr = 2.0 # by default we using Noam scheduling, the LR is a multiplier \n",
    "\n",
    "OmegaConf.save(conf, config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "703c548b-76b3-4a14-9766-5f5ad4177ccd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric_definitions=[\n",
    "     {\"Name\": \"train_runtime\", \"Regex\": \"train_runtime.*=\\D*(.*?)$\"},\n",
    "     {'Name': 'train_samples_per_second', 'Regex': \"train_samples_per_second.*=\\D*(.*?)$\"},\n",
    "     {'Name': 'epoch', 'Regex': \"epoch.*=\\D*(.*?)$\"},\n",
    "     {'Name': 'f1', 'Regex': \"f1.*=\\D*(.*?)$\"},\n",
    "     {'Name': 'exact_match', 'Regex': \"exact_match.*=\\D*(.*?)$\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b0ca1af6-03a3-4b36-894b-618d45dda8d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment_name = 'nemo-exp1'\n",
    "\n",
    "training_instance_type = 'ml.p3.16xlarge'\n",
    "# training_instance_type = 'local_gpu'\n",
    "training_instance_count = 1\n",
    "\n",
    "do_spot_training = False\n",
    "max_wait = None\n",
    "max_run = 1*60*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e7695db6-ffcd-477a-bb2e-10300d13a3a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kwargs = {}\n",
    "checkpoint_s3_uri = None\n",
    "\n",
    "if training_instance_type =='local_gpu':\n",
    "    from sagemaker.local import LocalSession\n",
    "    import os\n",
    "    \n",
    "    sagemaker_session = LocalSession()\n",
    "    sagemaker_session.config = {'local': {'local_code': True}}\n",
    "    \n",
    "    data_channels = {\"training\": f\"file://{data_dir}\", \"testing\": f\"file://{data_dir}\"}\n",
    "    \n",
    "else:\n",
    "    sagemaker_session = sagemaker.Session()\n",
    "    data_channels = {\"training\": loc, \"testing\": loc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "87b558b6-7ebd-4632-a722-9a511fa09e23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment_name : nemo-exp1 \n",
      "train_instance_type : ml.p3.16xlarge \n",
      "train_instance_count : 1\n"
     ]
    }
   ],
   "source": [
    "print(\"experiment_name : {} \\ntrain_instance_type : {} \\ntrain_instance_count : {}\".format(experiment_name, training_instance_type, instance_count))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959da702",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5. Run training on SageMaker\n",
    "\n",
    "Pass the path of the training and validation data on S3 + the output directory on S3 to the PyTorch estimator, and call fit with the appropriate bucket locations for the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "84150bf0-eef1-4b18-a190-5a9e058fa24f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_uri='322537213286.dkr.ecr.us-west-2.amazonaws.com/pytorch-training:nemo-22-12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1d2e44e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "\n",
    "est = PyTorch(\n",
    "    entry_point=\"speech_to_text_ctc.py\", # the script we want to run\n",
    "    source_dir=os.getcwd() + '/an4_nemo_sagemaker/code', # where our conf/script is\n",
    "    role=role,\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=training_instance_count,\n",
    "    image_uri=image_uri,\n",
    "    # framework_version=\"1.13.1\", # version of PyTorch\n",
    "    # py_version=\"py39\",\n",
    "    volume_size=1024,\n",
    "    code_location = code_location,\n",
    "    output_path=output_path,\n",
    "    disable_profiler=True,\n",
    "    debugger_hook_config=False,\n",
    "    hyperparameters={'config-path': 'conf'},\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    checkpoint_s3_uri=checkpoint_s3_uri,\n",
    "    metric_definitions=metric_definitions,\n",
    "    max_run=max_run,\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4fbbd2c6-e4c9-4009-8a6b-f3fa8a639639",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': 's3://sagemaker-us-west-2-322537213286/an4',\n",
       " 'testing': 's3://sagemaker-us-west-2-322537213286/an4'}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c0c687f1-bca4-4132-bdc6-98be7781b5ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker:Creating training-job with name: nemo-exp1-0310-16201678465207\n"
     ]
    }
   ],
   "source": [
    "create_experiment(experiment_name)\n",
    "job_name = create_trial(experiment_name)\n",
    "\n",
    "if training_instance_type =='local_gpu':\n",
    "    est.checkpoint_s3_uri = None\n",
    "else:\n",
    "    est.checkpoint_s3_uri = f's3://{bucket}/checkpoints/'\n",
    "\n",
    "\n",
    "est.fit(\n",
    "    inputs=data_channels, \n",
    "    job_name=job_name,\n",
    "    experiment_config={\n",
    "      'TrialName': job_name,\n",
    "      'TrialComponentDisplayName': job_name,\n",
    "    },\n",
    "    wait=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3387d3ba-144f-455a-bfdc-61b08c796c00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_name=est.latest_training_job.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2abd44bd-5b74-43ac-8e93-b56a6793e533",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-10 16:20:08 Starting - Starting the training job......\n",
      "2023-03-10 16:21:07 Starting - Preparing the instances for training.........\n",
      "2023-03-10 16:22:10 Downloading - Downloading input data......................................................................................................................................................\n",
      "2023-03-10 16:47:48 Training - Training image download completed. Training in progress..\u001b[34m=============\u001b[0m\n",
      "\u001b[34m== PyTorch ==\u001b[0m\n",
      "\u001b[34m=============\u001b[0m\n",
      "\u001b[34mNVIDIA Release 22.12 (build 49968248)\u001b[0m\n",
      "\u001b[34mPyTorch Version 1.14.0a0+410ce96\u001b[0m\n",
      "\u001b[34mContainer image Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\u001b[0m\n",
      "\u001b[34mCopyright (c) 2014-2022 Facebook Inc.\u001b[0m\n",
      "\u001b[34mCopyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\u001b[0m\n",
      "\u001b[34mCopyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\u001b[0m\n",
      "\u001b[34mCopyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\u001b[0m\n",
      "\u001b[34mCopyright (c) 2011-2013 NYU                      (Clement Farabet)\u001b[0m\n",
      "\u001b[34mCopyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\u001b[0m\n",
      "\u001b[34mCopyright (c) 2006      Idiap Research Institute (Samy Bengio)\u001b[0m\n",
      "\u001b[34mCopyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\u001b[0m\n",
      "\u001b[34mCopyright (c) 2015      Google Inc.\u001b[0m\n",
      "\u001b[34mCopyright (c) 2015      Yangqing Jia\u001b[0m\n",
      "\u001b[34mCopyright (c) 2013-2016 The Caffe contributors\u001b[0m\n",
      "\u001b[34mAll rights reserved.\u001b[0m\n",
      "\u001b[34mVarious files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\u001b[0m\n",
      "\u001b[34mThis container image and its contents are governed by the NVIDIA Deep Learning Container License.\u001b[0m\n",
      "\u001b[34mBy pulling and using the container, you accept the terms and conditions of this license:\u001b[0m\n",
      "\u001b[34mhttps://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\u001b[0m\n",
      "\u001b[34mNOTE: CUDA Forward Compatibility mode ENABLED.\n",
      "  Using CUDA 11.8 driver version 520.61.05 with kernel driver version 515.65.07.\n",
      "  See https://docs.nvidia.com/deploy/cuda-compatibility/ for details.\u001b[0m\n",
      "\u001b[34m2023-03-10 16:47:51,969 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-03-10 16:47:52,055 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-03-10 16:47:52,140 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-03-10 16:47:52,155 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"testing\": \"/opt/ml/input/data/testing\",\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p3.16xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": null,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"config-path\": \"conf\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"testing\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p3.16xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"job_name\": \"nemo-exp1-0310-16201678465207\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-322537213286/nemo-test/backup_codes/nemo-exp1-0310-16201678465207/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"speech_to_text_ctc\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 64,\n",
      "    \"num_gpus\": 8,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.16xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.16xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"speech_to_text_ctc.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"config-path\":\"conf\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=speech_to_text_ctc.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"testing\",\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.p3.16xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=speech_to_text_ctc\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=64\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-322537213286/nemo-test/backup_codes/nemo-exp1-0310-16201678465207/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"testing\":\"/opt/ml/input/data/testing\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.p3.16xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":null,\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"config-path\":\"conf\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"job_name\":\"nemo-exp1-0310-16201678465207\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-322537213286/nemo-test/backup_codes/nemo-exp1-0310-16201678465207/source/sourcedir.tar.gz\",\"module_name\":\"speech_to_text_ctc\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"speech_to_text_ctc.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--config-path\",\"conf\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TESTING=/opt/ml/input/data/testing\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_CONFIG-PATH=conf\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python38.zip:/usr/lib/python3.8:/usr/lib/python3.8/lib-dynload:/usr/local/lib/python3.8/dist-packages:/usr/local/lib/python3.8/dist-packages/torchaudio-0.14.0-py3.8-linux-x86_64.egg:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python speech_to_text_ctc.py --config-path conf\u001b[0m\n",
      "\u001b[34m2023-03-10 16:47:52,156 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2023-03-10 16:47:52,156 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mGet:1 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\u001b[0m\n",
      "\u001b[34mGet:2 http://archive.ubuntu.com/ubuntu focal InRelease [265 kB]\u001b[0m\n",
      "\u001b[34mGet:3 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [28.5 kB]\u001b[0m\n",
      "\u001b[34mGet:4 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\u001b[0m\n",
      "\u001b[34mGet:5 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [1998 kB]\u001b[0m\n",
      "\u001b[34mGet:6 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\u001b[0m\n",
      "\u001b[34mGet:7 http://archive.ubuntu.com/ubuntu focal/main amd64 Packages [1275 kB]\u001b[0m\n",
      "\u001b[34mGet:8 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2539 kB]\u001b[0m\n",
      "\u001b[34mGet:9 http://archive.ubuntu.com/ubuntu focal/restricted amd64 Packages [33.4 kB]\u001b[0m\n",
      "\u001b[34mGet:10 http://archive.ubuntu.com/ubuntu focal/universe amd64 Packages [11.3 MB]\u001b[0m\n",
      "\u001b[34mGet:11 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1015 kB]\u001b[0m\n",
      "\u001b[34mGet:12 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [177 kB]\u001b[0m\n",
      "\u001b[34mGet:13 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2134 kB]\u001b[0m\n",
      "\u001b[34mGet:14 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1311 kB]\u001b[0m\n",
      "\u001b[34mGet:15 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3014 kB]\u001b[0m\n",
      "\u001b[34mGet:16 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [31.2 kB]\u001b[0m\n",
      "\u001b[34mGet:17 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [28.6 kB]\u001b[0m\n",
      "\u001b[34mGet:18 http://archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [55.2 kB]\u001b[0m\n",
      "\u001b[34mFetched 25.6 MB in 2s (10.3 MB/s)\u001b[0m\n",
      "\u001b[34mReading package lists...\u001b[0m\n",
      "\u001b[34mReading package lists...\u001b[0m\n",
      "\u001b[34mBuilding dependency tree...\u001b[0m\n",
      "\u001b[34mReading state information...\u001b[0m\n",
      "\u001b[34mlibsndfile1 is already the newest version (1.0.28-7ubuntu0.1).\u001b[0m\n",
      "\u001b[34mffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\u001b[0m\n",
      "\u001b[34m0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\u001b[0m\n",
      "\u001b[34m[NeMo W 2023-03-10 16:48:01 optimizers:66] Could not import distributed_fused_adam optimizer from Apex\u001b[0m\n",
      "\u001b[34m[NeMo W 2023-03-10 16:48:02 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\u001b[0m\n",
      "\u001b[34m[NeMo W 2023-03-10 16:48:03 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "    See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "      ret = run_job(\n",
      "    \u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:03 speech_to_text_ctc:83] Hydra config: name: Conformer-CTC-Char1\n",
      "    model:\n",
      "      sample_rate: 16000\n",
      "      labels:\n",
      "      - ' '\n",
      "      - a\n",
      "      - b\n",
      "      - c\n",
      "      - d\n",
      "      - e\n",
      "      - f\n",
      "      - g\n",
      "      - h\n",
      "      - i\n",
      "      - j\n",
      "      - k\n",
      "      - l\n",
      "      - m\n",
      "      - 'n'\n",
      "      - o\n",
      "      - p\n",
      "      - q\n",
      "      - r\n",
      "      - s\n",
      "      - t\n",
      "      - u\n",
      "      - v\n",
      "      - w\n",
      "      - x\n",
      "      - 'y'\n",
      "      - z\n",
      "      - ''''\n",
      "      log_prediction: true\n",
      "      ctc_reduction: mean_batch\n",
      "      skip_nan_grad: false\n",
      "      train_ds:\n",
      "        manifest_filepath: /opt/ml/input/data/training/an4/train_manifest.json\n",
      "        labels: ${model.labels}\n",
      "        sample_rate: ${model.sample_rate}\n",
      "        batch_size: 16\n",
      "        shuffle: true\n",
      "        num_workers: 8\n",
      "        pin_memory: true\n",
      "        trim_silence: false\n",
      "        max_duration: 16.7\n",
      "        min_duration: 0.1\n",
      "        is_tarred: false\n",
      "        tarred_audio_filepaths: null\n",
      "        shuffle_n: 2048\n",
      "        bucketing_strategy: synced_randomized\n",
      "        bucketing_batch_size: null\n",
      "      validation_ds:\n",
      "        manifest_filepath: /opt/ml/input/data/testing/an4/test_manifest.json\n",
      "        labels: ${model.labels}\n",
      "        sample_rate: ${model.sample_rate}\n",
      "        batch_size: 16\n",
      "        shuffle: false\n",
      "        num_workers: 8\n",
      "        pin_memory: true\n",
      "      test_ds:\n",
      "        manifest_filepath: null\n",
      "        labels: ${model.labels}\n",
      "        sample_rate: ${model.sample_rate}\n",
      "        batch_size: 16\n",
      "        shuffle: false\n",
      "        num_workers: 8\n",
      "        pin_memory: true\n",
      "      preprocessor:\n",
      "        _target_: nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor\n",
      "        sample_rate: ${model.sample_rate}\n",
      "        normalize: per_feature\n",
      "        window_size: 0.025\n",
      "        window_stride: 0.01\n",
      "        window: hann\n",
      "        features: 80\n",
      "        n_fft: 512\n",
      "        log: true\n",
      "        frame_splicing: 1\n",
      "        dither: 1.0e-05\n",
      "        pad_to: 0\n",
      "        pad_value: 0.0\n",
      "      spec_augment:\n",
      "        _target_: nemo.collections.asr.modules.SpectrogramAugmentation\n",
      "        freq_masks: 2\n",
      "        time_masks: 5\n",
      "        freq_width: 27\n",
      "        time_width: 0.05\n",
      "      encoder:\n",
      "        _target_: nemo.collections.asr.modules.ConformerEncoder\n",
      "        feat_in: ${model.preprocessor.features}\n",
      "        feat_out: -1\n",
      "        n_layers: 8\n",
      "        d_model: 256\n",
      "        subsampling: striding\n",
      "        subsampling_factor: 4\n",
      "        subsampling_conv_channels: -1\n",
      "        causal_downsampling: false\n",
      "        ff_expansion_factor: 4\n",
      "        self_attention_model: rel_pos\n",
      "        n_heads: 8\n",
      "        att_context_size:\n",
      "        - -1\n",
      "        - -1\n",
      "        att_context_style: regular\n",
      "        xscaling: true\n",
      "        untie_biases: true\n",
      "        pos_emb_max_len: 5000\n",
      "        conv_kernel_size: 31\n",
      "        conv_norm_type: batch_norm\n",
      "        conv_context_size: null\n",
      "        dropout: 0.1\n",
      "        dropout_pre_encoder: 0.1\n",
      "        dropout_emb: 0.0\n",
      "        dropout_att: 0.1\n",
      "        stochastic_depth_drop_prob: 0.0\n",
      "        stochastic_depth_mode: linear\n",
      "        stochastic_depth_start_layer: 1\n",
      "      decoder:\n",
      "        _target_: nemo.collections.asr.modules.ConvASRDecoder\n",
      "        feat_in: null\n",
      "        num_classes: -1\n",
      "        vocabulary: ${model.labels}\n",
      "      interctc:\n",
      "        loss_weights: []\n",
      "        apply_at_layers: []\n",
      "      optim:\n",
      "        name: adamw\n",
      "        lr: 2.0\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.98\n",
      "        weight_decay: 0.001\n",
      "        sched:\n",
      "          name: NoamAnnealing\n",
      "          d_model: ${model.encoder.d_model}\n",
      "          warmup_steps: 10000\n",
      "          warmup_ratio: null\n",
      "          min_lr: 1.0e-06\n",
      "      n_heads: 4\n",
      "    trainer:\n",
      "      devices: -1\n",
      "      num_nodes: 1\n",
      "      max_epochs: 5\n",
      "      max_steps: -1\n",
      "      val_check_interval: 1.0\n",
      "      accelerator: gpu\n",
      "      strategy: ddp\n",
      "      accumulate_grad_batches: 1\n",
      "      gradient_clip_val: 0.0\n",
      "      precision: 32\n",
      "      log_every_n_steps: 10\n",
      "      enable_progress_bar: true\n",
      "      resume_from_checkpoint: null\n",
      "      num_sanity_val_steps: 0\n",
      "      check_val_every_n_epoch: 1\n",
      "      sync_batchnorm: true\n",
      "      enable_checkpointing: false\n",
      "      logger: false\n",
      "      benchmark: false\n",
      "    exp_manager:\n",
      "      exp_dir: /opt/ml/model/\n",
      "      name: ${name}\n",
      "      create_tensorboard_logger: true\n",
      "      create_checkpoint_callback: true\n",
      "      checkpoint_callback_params:\n",
      "        monitor: val_wer\n",
      "        mode: min\n",
      "        save_top_k: 5\n",
      "        always_save_nemo: true\n",
      "      resume_if_exists: false\n",
      "      resume_ignore_no_checkpoint: false\n",
      "      create_wandb_logger: false\n",
      "      wandb_logger_kwargs:\n",
      "        name: null\n",
      "        project: null\n",
      "    \u001b[0m\n",
      "\u001b[34mGPU available: True (cuda), used: True\u001b[0m\n",
      "\u001b[34mTPU available: False, using: 0 TPU cores\u001b[0m\n",
      "\u001b[34mIPU available: False, using: 0 IPUs\u001b[0m\n",
      "\u001b[34mHPU available: False, using: 0 HPUs\u001b[0m\n",
      "\u001b[34m`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:03 exp_manager:382] Experiments will be logged at /opt/ml/model/Conformer-CTC-Char1/2023-03-10_16-48-03\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:03 exp_manager:800] TensorboardLogger has been set up\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:04 collections:193] Dataset loaded with 948 files totalling 0.71 hours\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:04 collections:194] 0 files were filtered totalling 0.00 hours\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:04 collections:193] Dataset loaded with 130 files totalling 0.10 hours\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:04 collections:194] 0 files were filtered totalling 0.00 hours\u001b[0m\n",
      "\u001b[34m[NeMo W 2023-03-10 16:48:04 audio_to_text_dataset:547] Could not load dataset as `manifest_filepath` was None. Provided config : {'manifest_filepath': None, 'labels': [' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\"], 'sample_rate': 16000, 'batch_size': 16, 'shuffle': False, 'num_workers': 8, 'pin_memory': True}\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:04 features:286] PADDING: 0\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:04 ctc_models:64] \n",
      "    Replacing placeholder number of classes (-1) with actual number of classes - 28\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:04 conv_asr:428] num_classes of ConvASRDecoder is set to the size of the vocabulary: 28.\u001b[0m\n",
      "\u001b[34mHit:1 http://security.ubuntu.com/ubuntu focal-security InRelease\u001b[0m\n",
      "\u001b[34mHit:2 http://archive.ubuntu.com/ubuntu focal InRelease\u001b[0m\n",
      "\u001b[34mHit:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease\u001b[0m\n",
      "\u001b[34mHit:4 http://archive.ubuntu.com/ubuntu focal-backports InRelease\u001b[0m\n",
      "\u001b[34mReading package lists...\u001b[0m\n",
      "\u001b[34mReading package lists...\u001b[0m\n",
      "\u001b[34mBuilding dependency tree...\u001b[0m\n",
      "\u001b[34mReading state information...\u001b[0m\n",
      "\u001b[34mlibsndfile1 is already the newest version (1.0.28-7ubuntu0.1).\u001b[0m\n",
      "\u001b[34mffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\u001b[0m\n",
      "\u001b[34m0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\u001b[0m\n",
      "\u001b[34mHit:1 http://security.ubuntu.com/ubuntu focal-security InRelease\u001b[0m\n",
      "\u001b[34mHit:2 http://archive.ubuntu.com/ubuntu focal InRelease\u001b[0m\n",
      "\u001b[34mHit:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease\u001b[0m\n",
      "\u001b[34mHit:4 http://archive.ubuntu.com/ubuntu focal-backports InRelease\u001b[0m\n",
      "\u001b[34mReading package lists...\u001b[0m\n",
      "\u001b[34mInitializing distributed: GLOBAL_RANK: 1, MEMBER: 2/8\u001b[0m\n",
      "\u001b[34mReading package lists...\u001b[0m\n",
      "\u001b[34mBuilding dependency tree...\u001b[0m\n",
      "\u001b[34mReading state information...\u001b[0m\n",
      "\u001b[34mlibsndfile1 is already the newest version (1.0.28-7ubuntu0.1).\u001b[0m\n",
      "\u001b[34mffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\u001b[0m\n",
      "\u001b[34m0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\u001b[0m\n",
      "\u001b[34mHit:1 http://archive.ubuntu.com/ubuntu focal InRelease\u001b[0m\n",
      "\u001b[34mHit:2 http://security.ubuntu.com/ubuntu focal-security InRelease\u001b[0m\n",
      "\u001b[34mHit:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease\u001b[0m\n",
      "\u001b[34mHit:4 http://archive.ubuntu.com/ubuntu focal-backports InRelease\u001b[0m\n",
      "\u001b[34mReading package lists...\u001b[0m\n",
      "\u001b[34mReading package lists...\u001b[0m\n",
      "\u001b[34mBuilding dependency tree...\u001b[0m\n",
      "\u001b[34mReading state information...\u001b[0m\n",
      "\u001b[34mlibsndfile1 is already the newest version (1.0.28-7ubuntu0.1).\u001b[0m\n",
      "\u001b[34mffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\u001b[0m\n",
      "\u001b[34m0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\u001b[0m\n",
      "\u001b[34mInitializing distributed: GLOBAL_RANK: 2, MEMBER: 3/8\u001b[0m\n",
      "\u001b[34mHit:1 http://security.ubuntu.com/ubuntu focal-security InRelease\u001b[0m\n",
      "\u001b[34mHit:2 http://archive.ubuntu.com/ubuntu focal InRelease\u001b[0m\n",
      "\u001b[34mHit:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease\u001b[0m\n",
      "\u001b[34mHit:4 http://archive.ubuntu.com/ubuntu focal-backports InRelease\u001b[0m\n",
      "\u001b[34mReading package lists...\u001b[0m\n",
      "\u001b[34mInitializing distributed: GLOBAL_RANK: 3, MEMBER: 4/8\u001b[0m\n",
      "\u001b[34mReading package lists...\u001b[0m\n",
      "\u001b[34mBuilding dependency tree...\u001b[0m\n",
      "\u001b[34mReading state information...\u001b[0m\n",
      "\u001b[34mlibsndfile1 is already the newest version (1.0.28-7ubuntu0.1).\u001b[0m\n",
      "\u001b[34mffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\u001b[0m\n",
      "\u001b[34m0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\u001b[0m\n",
      "\u001b[34mHit:1 http://security.ubuntu.com/ubuntu focal-security InRelease\u001b[0m\n",
      "\u001b[34mHit:2 http://archive.ubuntu.com/ubuntu focal InRelease\u001b[0m\n",
      "\u001b[34mHit:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease\u001b[0m\n",
      "\u001b[34mHit:4 http://archive.ubuntu.com/ubuntu focal-backports InRelease\u001b[0m\n",
      "\u001b[34mReading package lists...\u001b[0m\n",
      "\u001b[34mReading package lists...\u001b[0m\n",
      "\u001b[34mBuilding dependency tree...\u001b[0m\n",
      "\u001b[34mReading state information...\u001b[0m\n",
      "\u001b[34mlibsndfile1 is already the newest version (1.0.28-7ubuntu0.1).\u001b[0m\n",
      "\u001b[34mffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\u001b[0m\n",
      "\u001b[34m0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\u001b[0m\n",
      "\u001b[34mInitializing distributed: GLOBAL_RANK: 4, MEMBER: 5/8\u001b[0m\n",
      "\u001b[34mHit:1 http://archive.ubuntu.com/ubuntu focal InRelease\u001b[0m\n",
      "\u001b[34mHit:2 http://security.ubuntu.com/ubuntu focal-security InRelease\u001b[0m\n",
      "\u001b[34mHit:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease\u001b[0m\n",
      "\u001b[34mHit:4 http://archive.ubuntu.com/ubuntu focal-backports InRelease\u001b[0m\n",
      "\u001b[34mReading package lists...\u001b[0m\n",
      "\u001b[34mInitializing distributed: GLOBAL_RANK: 5, MEMBER: 6/8\u001b[0m\n",
      "\u001b[34mReading package lists...\u001b[0m\n",
      "\u001b[34mBuilding dependency tree...\u001b[0m\n",
      "\u001b[34mReading state information...\u001b[0m\n",
      "\u001b[34mlibsndfile1 is already the newest version (1.0.28-7ubuntu0.1).\u001b[0m\n",
      "\u001b[34mffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\u001b[0m\n",
      "\u001b[34m0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\u001b[0m\n",
      "\u001b[34mHit:1 http://security.ubuntu.com/ubuntu focal-security InRelease\u001b[0m\n",
      "\u001b[34mHit:2 http://archive.ubuntu.com/ubuntu focal InRelease\u001b[0m\n",
      "\u001b[34mInitializing distributed: GLOBAL_RANK: 0, MEMBER: 1/8\u001b[0m\n",
      "\u001b[34mHit:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease\u001b[0m\n",
      "\u001b[34mAdded key: store_based_barrier_key:1 to store for rank: 5\u001b[0m\n",
      "\u001b[34mHit:4 http://archive.ubuntu.com/ubuntu focal-backports InRelease\u001b[0m\n",
      "\u001b[34mAdded key: store_based_barrier_key:1 to store for rank: 2\u001b[0m\n",
      "\u001b[34mAdded key: store_based_barrier_key:1 to store for rank: 1\u001b[0m\n",
      "\u001b[34mReading package lists...Added key: store_based_barrier_key:1 to store for rank: 3\u001b[0m\n",
      "\u001b[34mAdded key: store_based_barrier_key:1 to store for rank: 4\u001b[0m\n",
      "\u001b[34mReading package lists...\u001b[0m\n",
      "\u001b[34mBuilding dependency tree...\u001b[0m\n",
      "\u001b[34mReading state information...\u001b[0m\n",
      "\u001b[34mlibsndfile1 is already the newest version (1.0.28-7ubuntu0.1).\u001b[0m\n",
      "\u001b[34mffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\u001b[0m\n",
      "\u001b[34m0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\u001b[0m\n",
      "\u001b[34mInitializing distributed: GLOBAL_RANK: 6, MEMBER: 7/8\u001b[0m\n",
      "\u001b[34mAdded key: store_based_barrier_key:1 to store for rank: 6\u001b[0m\n",
      "\u001b[34mInitializing distributed: GLOBAL_RANK: 7, MEMBER: 8/8\u001b[0m\n",
      "\u001b[34mAdded key: store_based_barrier_key:1 to store for rank: 7\u001b[0m\n",
      "\u001b[34mAdded key: store_based_barrier_key:1 to store for rank: 0\u001b[0m\n",
      "\u001b[34mRank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.\u001b[0m\n",
      "\u001b[34m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34mdistributed_backend=nccl\u001b[0m\n",
      "\u001b[34mAll distributed processes registered. Starting with 8 processes\u001b[0m\n",
      "\u001b[34m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34mRank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.\u001b[0m\n",
      "\u001b[34mRank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.\u001b[0m\n",
      "\u001b[34mRank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.\u001b[0m\n",
      "\u001b[34mRank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.\u001b[0m\n",
      "\u001b[34mRank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.\u001b[0m\n",
      "\u001b[34mRank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.\u001b[0m\n",
      "\u001b[34mRank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.\u001b[0m\n",
      "\u001b[34mLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\u001b[0m\n",
      "\u001b[34mLOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\u001b[0m\n",
      "\u001b[34mLOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\u001b[0m\n",
      "\u001b[34mLOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\u001b[0m\n",
      "\u001b[34mLOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\u001b[0m\n",
      "\u001b[34mLOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\u001b[0m\n",
      "\u001b[34mLOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\u001b[0m\n",
      "\u001b[34mLOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:42 modelPT:722] Optimizer config = AdamW (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.98]\n",
      "        capturable: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        lr: 2.0\n",
      "        maximize: False\n",
      "        weight_decay: 0.001\n",
      "    )\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:42 lr_scheduler:910] Scheduler \"<nemo.core.optim.lr_scheduler.NoamAnnealing object at 0x7f92c53894f0>\" \n",
      "    will be used during training (effective maximum steps = 40) - \n",
      "    Parameters : \n",
      "    (d_model: 256\n",
      "    warmup_steps: 10000\n",
      "    warmup_ratio: null\n",
      "    min_lr: 1.0e-06\n",
      "    max_steps: 40\n",
      "    )\n",
      "  | Name              | Type                              | Params\u001b[0m\n",
      "\u001b[34m------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m0 | preprocessor      | AudioToMelSpectrogramPreprocessor | 0     \u001b[0m\n",
      "\u001b[34m1 | encoder           | ConformerEncoder                  | 14.6 M\u001b[0m\n",
      "\u001b[34m2 | decoder           | ConvASRDecoder                    | 7.5 K \u001b[0m\n",
      "\u001b[34m3 | loss              | CTCLoss                           | 0     \u001b[0m\n",
      "\u001b[34m4 | spec_augmentation | SpectrogramAugmentation           | 0     \u001b[0m\n",
      "\u001b[34m5 | _wer              | WER                               | 0     \u001b[0m\n",
      "\u001b[34m------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m14.6 M    Trainable params\u001b[0m\n",
      "\u001b[34m0         Non-trainable params\u001b[0m\n",
      "\u001b[34m14.6 M    Total params\u001b[0m\n",
      "\u001b[34m58.492    Total estimated model params size (MB)\u001b[0m\n",
      "\u001b[34m[NeMo W 2023-03-10 16:48:42 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py:1595: PossibleUserWarning: The number of training batches (8) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "      rank_zero_warn(\n",
      "    \u001b[0m\n",
      "\u001b[34m[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m#015Training: 0it [00:00, ?it/s]#015Training:   0%|          | 0/10 [00:00<?, ?it/s]#015Epoch 0:   0%|          | 0/10 [00:00<?, ?it/s] #015Epoch 0:  10%|█         | 1/10 [00:01<00:15,  1.70s/it]#015Epoch 0:  10%|█         | 1/10 [00:01<00:15,  1.70s/it, loss=174, v_num=8-03]#015Epoch 0:  20%|██        | 2/10 [00:01<00:07,  1.02it/s, loss=174, v_num=8-03]#015Epoch 0:  20%|██        | 2/10 [00:01<00:07,  1.02it/s, loss=167, v_num=8-03]#015Epoch 0:  30%|███       | 3/10 [00:02<00:05,  1.39it/s, loss=167, v_num=8-03]#015Epoch 0:  30%|███       | 3/10 [00:02<00:05,  1.39it/s, loss=172, v_num=8-03]#015Epoch 0:  40%|████      | 4/10 [00:02<00:03,  1.71it/s, loss=172, v_num=8-03]#015Epoch 0:  40%|████      | 4/10 [00:02<00:03,  1.71it/s, loss=176, v_num=8-03]#015Epoch 0:  50%|█████     | 5/10 [00:02<00:02,  1.97it/s, loss=176, v_num=8-03]#015Epoch 0:  50%|█████     | 5/10 [00:02<00:02,  1.97it/s, loss=182, v_num=8-03]#015Epoch 0:  60%|██████    | 6/10 [00:02<00:01,  2.20it/s, loss=182, v_num=8-03]#015Epoch 0:  60%|██████    | 6/10 [00:02<00:01,  2.20it/s, loss=184, v_num=8-03]#015Epoch 0:  70%|███████   | 7/10 [00:02<00:01,  2.40it/s, loss=184, v_num=8-03]#015Epoch 0:  70%|███████   | 7/10 [00:02<00:01,  2.40it/s, loss=181, v_num=8-03]#015Epoch 0:  80%|████████  | 8/10 [00:03<00:00,  2.54it/s, loss=181, v_num=8-03]#015Epoch 0:  80%|████████  | 8/10 [00:03<00:00,  2.54it/s, loss=179, v_num=8-03]\u001b[0m\n",
      "\u001b[34m#015Validation: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validation:   0%|          | 0/2 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]#033[A[NeMo I 2023-03-10 16:48:45 wer:1168] \n",
      "    \u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:45 wer:1169] reference:rubout g m e f three nine\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:45 wer:1170] predicted:rgnjrvjrjrgejrjrjrjrvjvjrvjzjrejrjrvrcjgjgvyrv\u001b[0m\n",
      "\u001b[34m#015Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  3.62it/s]#033[A#015Epoch 0:  90%|█████████ | 9/10 [00:03<00:00,  2.47it/s, loss=179, v_num=8-03][NeMo I 2023-03-10 16:48:45 wer:1168] \n",
      "    \u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:45 wer:1169] reference:four one two two six eight four one four two\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:45 wer:1170] predicted:rjvpzpzjnjrnjrjnjjrjrjzzjrjgjvjnjgr\u001b[0m\n",
      "\u001b[34m[NeMo W 2023-03-10 16:48:45 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:537: PossibleUserWarning: It is recommended to use `self.log('global_step', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "      warning_cache.warn(\n",
      "    \u001b[0m\n",
      "\u001b[34m[NeMo W 2023-03-10 16:48:45 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:537: PossibleUserWarning: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "      warning_cache.warn(\n",
      "    \u001b[0m\n",
      "\u001b[34m[NeMo W 2023-03-10 16:48:45 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:537: PossibleUserWarning: It is recommended to use `self.log('val_wer', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "      warning_cache.warn(\n",
      "    \u001b[0m\n",
      "\u001b[34m#015Validation DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  5.74it/s]#033[A#015Epoch 0: 100%|██████████| 10/10 [00:03<00:00,  2.69it/s, loss=179, v_num=8-03]#015Epoch 0: 100%|██████████| 10/10 [00:03<00:00,  2.68it/s, loss=179, v_num=8-03]\u001b[0m\n",
      "\u001b[34mEpoch 0, global step 8: 'val_wer' reached 1.00000 (best 1.00000), saving model to '/opt/ml/model/Conformer-CTC-Char1/2023-03-10_16-48-03/checkpoints/Conformer-CTC-Char1--val_wer=1.0000-epoch=0.ckpt' as top 5\u001b[0m\n",
      "\u001b[34m#015                                                                      #033[A[NeMo I 2023-03-10 16:48:46 exp_manager:981] New .nemo model saved to: /opt/ml/model/Conformer-CTC-Char1/2023-03-10_16-48-03/checkpoints/Conformer-CTC-Char1.nemo\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:47 exp_manager:981] New .nemo model saved to: /opt/ml/model/Conformer-CTC-Char1/2023-03-10_16-48-03/checkpoints/Conformer-CTC-Char1.nemo\u001b[0m\n",
      "\u001b[34m#015Epoch 0: 100%|██████████| 10/10 [00:05<00:00,  1.87it/s, loss=179, v_num=8-03]#015Epoch 0:   0%|          | 0/10 [00:00<?, ?it/s, loss=179, v_num=8-03]         #015Epoch 1:   0%|          | 0/10 [00:00<?, ?it/s, loss=179, v_num=8-03]#015Epoch 1:  10%|█         | 1/10 [00:00<00:03,  2.43it/s, loss=179, v_num=8-03]#015Epoch 1:  10%|█         | 1/10 [00:00<00:03,  2.43it/s, loss=174, v_num=8-03]#015Epoch 1:  20%|██        | 2/10 [00:00<00:02,  3.32it/s, loss=174, v_num=8-03]#015Epoch 1:  20%|██        | 2/10 [00:00<00:02,  3.31it/s, loss=174, v_num=8-03]#015Epoch 1:  30%|███       | 3/10 [00:00<00:01,  3.79it/s, loss=174, v_num=8-03]#015Epoch 1:  30%|███       | 3/10 [00:00<00:01,  3.78it/s, loss=172, v_num=8-03]#015Epoch 1:  40%|████      | 4/10 [00:00<00:01,  4.08it/s, loss=172, v_num=8-03]#015Epoch 1:  40%|████      | 4/10 [00:00<00:01,  4.08it/s, loss=170, v_num=8-03]#015Epoch 1:  50%|█████     | 5/10 [00:01<00:01,  4.28it/s, loss=170, v_num=8-03]#015Epoch 1:  50%|█████     | 5/10 [00:01<00:01,  4.28it/s, loss=166, v_num=8-03]#015Epoch 1:  60%|██████    | 6/10 [00:01<00:00,  4.43it/s, loss=166, v_num=8-03]#015Epoch 1:  60%|██████    | 6/10 [00:01<00:00,  4.43it/s, loss=166, v_num=8-03]#015Epoch 1:  70%|███████   | 7/10 [00:01<00:00,  4.55it/s, loss=166, v_num=8-03]#015Epoch 1:  70%|███████   | 7/10 [00:01<00:00,  4.55it/s, loss=165, v_num=8-03]#015Epoch 1:  80%|████████  | 8/10 [00:01<00:00,  4.59it/s, loss=165, v_num=8-03]#015Epoch 1:  80%|████████  | 8/10 [00:01<00:00,  4.59it/s, loss=163, v_num=8-03]\u001b[0m\n",
      "\u001b[34m#015Validation: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validation:   0%|          | 0/2 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]#033[A[NeMo I 2023-03-10 16:48:49 wer:1168] \n",
      "    \u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:49 wer:1169] reference:rubout g m e f three nine\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:49 wer:1170] predicted:jjejrjjjjjjjj\u001b[0m\n",
      "\u001b[34m#015Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  3.48it/s]#033[A#015Epoch 1:  90%|█████████ | 9/10 [00:02<00:00,  3.86it/s, loss=163, v_num=8-03][NeMo I 2023-03-10 16:48:49 wer:1168] \n",
      "    \u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:49 wer:1169] reference:four one two two six eight four one four two\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:49 wer:1170] predicted:jrrjjjrjjj\u001b[0m\n",
      "\u001b[34m#015Validation DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  5.96it/s]#033[A#015Epoch 1: 100%|██████████| 10/10 [00:02<00:00,  4.20it/s, loss=163, v_num=8-03]#015Epoch 1: 100%|██████████| 10/10 [00:02<00:00,  4.19it/s, loss=163, v_num=8-03]\u001b[0m\n",
      "\u001b[34mEpoch 1, global step 16: 'val_wer' reached 1.00000 (best 1.00000), saving model to '/opt/ml/model/Conformer-CTC-Char1/2023-03-10_16-48-03/checkpoints/Conformer-CTC-Char1--val_wer=1.0000-epoch=1.ckpt' as top 5\u001b[0m\n",
      "\u001b[34m#015                                                                      #033[A[NeMo I 2023-03-10 16:48:50 exp_manager:981] New .nemo model saved to: /opt/ml/model/Conformer-CTC-Char1/2023-03-10_16-48-03/checkpoints/Conformer-CTC-Char1.nemo\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:51 exp_manager:981] New .nemo model saved to: /opt/ml/model/Conformer-CTC-Char1/2023-03-10_16-48-03/checkpoints/Conformer-CTC-Char1.nemo\u001b[0m\n",
      "\u001b[34m#015Epoch 1: 100%|██████████| 10/10 [00:04<00:00,  2.22it/s, loss=163, v_num=8-03]#015Epoch 1:   0%|          | 0/10 [00:00<?, ?it/s, loss=163, v_num=8-03]         #015Epoch 2:   0%|          | 0/10 [00:00<?, ?it/s, loss=163, v_num=8-03]#015Epoch 2:  10%|█         | 1/10 [00:00<00:03,  2.28it/s, loss=163, v_num=8-03]#015Epoch 2:  10%|█         | 1/10 [00:00<00:03,  2.28it/s, loss=160, v_num=8-03]#015Epoch 2:  20%|██        | 2/10 [00:00<00:02,  3.20it/s, loss=160, v_num=8-03]#015Epoch 2:  20%|██        | 2/10 [00:00<00:02,  3.20it/s, loss=158, v_num=8-03]#015Epoch 2:  30%|███       | 3/10 [00:00<00:01,  3.70it/s, loss=158, v_num=8-03]#015Epoch 2:  30%|███       | 3/10 [00:00<00:01,  3.70it/s, loss=154, v_num=8-03]#015Epoch 2:  40%|████      | 4/10 [00:00<00:01,  4.03it/s, loss=154, v_num=8-03]#015Epoch 2:  40%|████      | 4/10 [00:00<00:01,  4.03it/s, loss=152, v_num=8-03]#015Epoch 2:  50%|█████     | 5/10 [00:01<00:01,  4.24it/s, loss=152, v_num=8-03]#015Epoch 2:  50%|█████     | 5/10 [00:01<00:01,  4.24it/s, loss=148, v_num=8-03]#015Epoch 2:  60%|██████    | 6/10 [00:01<00:00,  4.39it/s, loss=148, v_num=8-03]#015Epoch 2:  60%|██████    | 6/10 [00:01<00:00,  4.38it/s, loss=145, v_num=8-03]#015Epoch 2:  70%|███████   | 7/10 [00:01<00:00,  4.51it/s, loss=145, v_num=8-03]#015Epoch 2:  70%|███████   | 7/10 [00:01<00:00,  4.51it/s, loss=140, v_num=8-03]#015Epoch 2:  80%|████████  | 8/10 [00:01<00:00,  4.64it/s, loss=140, v_num=8-03]#015Epoch 2:  80%|████████  | 8/10 [00:01<00:00,  4.64it/s, loss=134, v_num=8-03]\u001b[0m\n",
      "\u001b[34m#015Validation: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validation:   0%|          | 0/2 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]#033[A[NeMo I 2023-03-10 16:48:54 wer:1168] \n",
      "    \u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:54 wer:1169] reference:rubout g m e f three nine\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:54 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34m#015Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  3.36it/s]#033[A#015Epoch 2:  90%|█████████ | 9/10 [00:02<00:00,  3.75it/s, loss=134, v_num=8-03][NeMo I 2023-03-10 16:48:54 wer:1168] \n",
      "    \u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:54 wer:1169] reference:four one two two six eight four one four two\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:54 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34m#015Validation DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  5.71it/s]#033[A#015Epoch 2: 100%|██████████| 10/10 [00:02<00:00,  4.07it/s, loss=134, v_num=8-03]#015Epoch 2: 100%|██████████| 10/10 [00:02<00:00,  4.06it/s, loss=134, v_num=8-03]\u001b[0m\n",
      "\u001b[34mEpoch 2, global step 24: 'val_wer' reached 1.00000 (best 1.00000), saving model to '/opt/ml/model/Conformer-CTC-Char1/2023-03-10_16-48-03/checkpoints/Conformer-CTC-Char1--val_wer=1.0000-epoch=2.ckpt' as top 5\u001b[0m\n",
      "\u001b[34m#015                                                                      #033[A[NeMo I 2023-03-10 16:48:54 exp_manager:981] New .nemo model saved to: /opt/ml/model/Conformer-CTC-Char1/2023-03-10_16-48-03/checkpoints/Conformer-CTC-Char1.nemo\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:55 exp_manager:981] New .nemo model saved to: /opt/ml/model/Conformer-CTC-Char1/2023-03-10_16-48-03/checkpoints/Conformer-CTC-Char1.nemo\u001b[0m\n",
      "\u001b[34m#015Epoch 2: 100%|██████████| 10/10 [00:04<00:00,  2.30it/s, loss=134, v_num=8-03]#015Epoch 2:   0%|          | 0/10 [00:00<?, ?it/s, loss=134, v_num=8-03]         #015Epoch 3:   0%|          | 0/10 [00:00<?, ?it/s, loss=134, v_num=8-03]#015Epoch 3:  10%|█         | 1/10 [00:00<00:04,  2.15it/s, loss=134, v_num=8-03]#015Epoch 3:  10%|█         | 1/10 [00:00<00:04,  2.14it/s, loss=127, v_num=8-03]#015Epoch 3:  20%|██        | 2/10 [00:00<00:02,  3.08it/s, loss=127, v_num=8-03]#015Epoch 3:  20%|██        | 2/10 [00:00<00:02,  3.08it/s, loss=121, v_num=8-03]#015Epoch 3:  30%|███       | 3/10 [00:00<00:01,  3.60it/s, loss=121, v_num=8-03]#015Epoch 3:  30%|███       | 3/10 [00:00<00:01,  3.59it/s, loss=116, v_num=8-03]#015Epoch 3:  40%|████      | 4/10 [00:01<00:01,  3.92it/s, loss=116, v_num=8-03]#015Epoch 3:  40%|████      | 4/10 [00:01<00:01,  3.92it/s, loss=112, v_num=8-03]#015Epoch 3:  50%|█████     | 5/10 [00:01<00:01,  4.16it/s, loss=112, v_num=8-03]#015Epoch 3:  50%|█████     | 5/10 [00:01<00:01,  4.16it/s, loss=108, v_num=8-03]#015Epoch 3:  60%|██████    | 6/10 [00:01<00:00,  4.32it/s, loss=108, v_num=8-03]#015Epoch 3:  60%|██████    | 6/10 [00:01<00:00,  4.32it/s, loss=103, v_num=8-03]#015Epoch 3:  70%|███████   | 7/10 [00:01<00:00,  4.46it/s, loss=103, v_num=8-03]#015Epoch 3:  70%|███████   | 7/10 [00:01<00:00,  4.46it/s, loss=99.2, v_num=8-03]#015Epoch 3:  80%|████████  | 8/10 [00:01<00:00,  4.62it/s, loss=99.2, v_num=8-03]#015Epoch 3:  80%|████████  | 8/10 [00:01<00:00,  4.62it/s, loss=94.8, v_num=8-03]\u001b[0m\n",
      "\u001b[34m#015Validation: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validation:   0%|          | 0/2 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]#033[A[NeMo I 2023-03-10 16:48:58 wer:1168] \n",
      "    \u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:58 wer:1169] reference:rubout g m e f three nine\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:58 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34m#015Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  3.39it/s]#033[A#015Epoch 3:  90%|█████████ | 9/10 [00:02<00:00,  3.83it/s, loss=94.8, v_num=8-03][NeMo I 2023-03-10 16:48:58 wer:1168] \n",
      "    \u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:58 wer:1169] reference:four one two two six eight four one four two\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:58 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34m#015Validation DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  5.83it/s]#033[A#015Epoch 3: 100%|██████████| 10/10 [00:02<00:00,  4.17it/s, loss=94.8, v_num=8-03]#015Epoch 3: 100%|██████████| 10/10 [00:02<00:00,  4.16it/s, loss=94.8, v_num=8-03]\u001b[0m\n",
      "\u001b[34mEpoch 3, global step 32: 'val_wer' reached 1.00000 (best 1.00000), saving model to '/opt/ml/model/Conformer-CTC-Char1/2023-03-10_16-48-03/checkpoints/Conformer-CTC-Char1--val_wer=1.0000-epoch=3.ckpt' as top 5\u001b[0m\n",
      "\u001b[34m#015                                                                      #033[A[NeMo I 2023-03-10 16:48:59 exp_manager:981] New .nemo model saved to: /opt/ml/model/Conformer-CTC-Char1/2023-03-10_16-48-03/checkpoints/Conformer-CTC-Char1.nemo\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:48:59 exp_manager:981] New .nemo model saved to: /opt/ml/model/Conformer-CTC-Char1/2023-03-10_16-48-03/checkpoints/Conformer-CTC-Char1.nemo\u001b[0m\n",
      "\u001b[34m#015Epoch 3: 100%|██████████| 10/10 [00:04<00:00,  2.43it/s, loss=94.8, v_num=8-03]#015Epoch 3:   0%|          | 0/10 [00:00<?, ?it/s, loss=94.8, v_num=8-03]         #015Epoch 4:   0%|          | 0/10 [00:00<?, ?it/s, loss=94.8, v_num=8-03]#015Epoch 4:  10%|█         | 1/10 [00:00<00:04,  2.16it/s, loss=94.8, v_num=8-03]#015Epoch 4:  10%|█         | 1/10 [00:00<00:04,  2.15it/s, loss=92.3, v_num=8-03]#015Epoch 4:  20%|██        | 2/10 [00:00<00:02,  3.09it/s, loss=92.3, v_num=8-03]#015Epoch 4:  20%|██        | 2/10 [00:00<00:02,  3.08it/s, loss=88.5, v_num=8-03]#015Epoch 4:  30%|███       | 3/10 [00:00<00:01,  3.59it/s, loss=88.5, v_num=8-03]#015Epoch 4:  30%|███       | 3/10 [00:00<00:01,  3.58it/s, loss=83.7, v_num=8-03]#015Epoch 4:  40%|████      | 4/10 [00:01<00:01,  3.91it/s, loss=83.7, v_num=8-03]#015Epoch 4:  40%|████      | 4/10 [00:01<00:01,  3.90it/s, loss=80.3, v_num=8-03]#015Epoch 4:  50%|█████     | 5/10 [00:01<00:01,  4.12it/s, loss=80.3, v_num=8-03]#015Epoch 4:  50%|█████     | 5/10 [00:01<00:01,  4.12it/s, loss=77.9, v_num=8-03]#015Epoch 4:  60%|██████    | 6/10 [00:01<00:00,  4.29it/s, loss=77.9, v_num=8-03]#015Epoch 4:  60%|██████    | 6/10 [00:01<00:00,  4.29it/s, loss=76.3, v_num=8-03]#015Epoch 4:  70%|███████   | 7/10 [00:01<00:00,  4.44it/s, loss=76.3, v_num=8-03]#015Epoch 4:  70%|███████   | 7/10 [00:01<00:00,  4.44it/s, loss=74.5, v_num=8-03]#015Epoch 4:  80%|████████  | 8/10 [00:01<00:00,  4.57it/s, loss=74.5, v_num=8-03]#015Epoch 4:  80%|████████  | 8/10 [00:01<00:00,  4.57it/s, loss=72.1, v_num=8-03]\u001b[0m\n",
      "\u001b[34m#015Validation: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validation:   0%|          | 0/2 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]#033[A[NeMo I 2023-03-10 16:49:02 wer:1168] \n",
      "    \u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:49:02 wer:1169] reference:rubout g m e f three nine\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:49:02 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34m#015Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  3.34it/s]#033[A#015Epoch 4:  90%|█████████ | 9/10 [00:02<00:00,  3.79it/s, loss=72.1, v_num=8-03][NeMo I 2023-03-10 16:49:02 wer:1168] \n",
      "    \u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:49:02 wer:1169] reference:four one two two six eight four one four two\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:49:02 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34m#015Validation DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  5.75it/s]#033[A#015Epoch 4: 100%|██████████| 10/10 [00:02<00:00,  4.12it/s, loss=72.1, v_num=8-03]#015Epoch 4: 100%|██████████| 10/10 [00:02<00:00,  4.12it/s, loss=72.1, v_num=8-03]\u001b[0m\n",
      "\u001b[34mEpoch 4, global step 40: 'val_wer' reached 1.00000 (best 1.00000), saving model to '/opt/ml/model/Conformer-CTC-Char1/2023-03-10_16-48-03/checkpoints/Conformer-CTC-Char1--val_wer=1.0000-epoch=4.ckpt' as top 5\u001b[0m\n",
      "\u001b[34m#015                                                                      #033[A[NeMo I 2023-03-10 16:49:03 exp_manager:981] New .nemo model saved to: /opt/ml/model/Conformer-CTC-Char1/2023-03-10_16-48-03/checkpoints/Conformer-CTC-Char1.nemo\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:49:04 exp_manager:981] New .nemo model saved to: /opt/ml/model/Conformer-CTC-Char1/2023-03-10_16-48-03/checkpoints/Conformer-CTC-Char1.nemo\u001b[0m\n",
      "\u001b[34m`Trainer.fit` stopped: `max_epochs=5` reached.\u001b[0m\n",
      "\u001b[34m#015Epoch 4: 100%|██████████| 10/10 [00:04<00:00,  2.46it/s, loss=72.1, v_num=8-03]#015Epoch 4: 100%|██████████| 10/10 [00:04<00:00,  2.46it/s, loss=72.1, v_num=8-03]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-10 16:49:04 exp_manager:981] New .nemo model saved to: /opt/ml/model/Conformer-CTC-Char1/2023-03-10_16-48-03/checkpoints/Conformer-CTC-Char1.nemo\u001b[0m\n",
      "\u001b[34m2023-03-10 16:49:08,005 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-03-10 16:49:14 Uploading - Uploading generated training model\n",
      "2023-03-10 16:51:35 Completed - Training job completed\n",
      "Training seconds: 1764\n",
      "Billable seconds: 1764\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "sagemaker_session.logs_for_job(job_name=job_name, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be67b8e",
   "metadata": {},
   "source": [
    "### 6. Download model, (Optional) Tensorboard Logs\n",
    "\n",
    "SageMaker stores our models/logs within a tar file after training has finished. These can be obtained from S3 like below.\n",
    "\n",
    "We also visualize the training logs. We suggest using an external logger (such as W&B) to track training progress during the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "81cd58d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "key = est.model_data.replace(\"s3://\" + bucket + '/', '')\n",
    "\n",
    "sagemaker_session.boto_session.client(\"s3\", region_name=region_name).download_file(\n",
    "    Bucket=bucket, Key=key, Filename='model.tar.gz',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "656d53f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conformer-CTC-Char1/\n",
      "Conformer-CTC-Char1/2023-03-10_16-48-03/\n",
      "Conformer-CTC-Char1/2023-03-10_16-48-03/hparams.yaml\n",
      "Conformer-CTC-Char1/2023-03-10_16-48-03/nemo_log_globalrank-1_localrank-1.txt\n",
      "Conformer-CTC-Char1/2023-03-10_16-48-03/nemo_log_globalrank-7_localrank-7.txt\n",
      "Conformer-CTC-Char1/2023-03-10_16-48-03/nemo_log_globalrank-5_localrank-5.txt\n",
      "Conformer-CTC-Char1/2023-03-10_16-48-03/nemo_error_log.txt\n",
      "Conformer-CTC-Char1/2023-03-10_16-48-03/nemo_log_globalrank-2_localrank-2.txt\n",
      "Conformer-CTC-Char1/2023-03-10_16-48-03/checkpoints/\n",
      "Conformer-CTC-Char1/2023-03-10_16-48-03/checkpoints/Conformer-CTC-Char1--val_wer=1.0000-epoch=2.ckpt\n",
      "Conformer-CTC-Char1/2023-03-10_16-48-03/checkpoints/Conformer-CTC-Char1--val_wer=1.0000-epoch=0.ckpt\n",
      "Conformer-CTC-Char1/2023-03-10_16-48-03/checkpoints/Conformer-CTC-Char1.nemo\n",
      "Conformer-CTC-Char1/2023-03-10_16-48-03/checkpoints/Conformer-CTC-Char1--val_wer=1.0000-epoch=3.ckpt\n",
      "Conformer-CTC-Char1/2023-03-10_16-48-03/checkpoints/Conformer-CTC-Char1--val_wer=1.0000-epoch=4.ckpt\n",
      "Conformer-CTC-Char1/2023-03-10_16-48-03/checkpoints/Conformer-CTC-Char1--val_wer=1.0000-epoch=1.ckpt\n",
      "Conformer-CTC-Char1/2023-03-10_16-48-03/checkpoints/Conformer-CTC-Char1--val_wer=1.0000-epoch=5-last.ckpt\n",
      "Conformer-CTC-Char1/2023-03-10_16-48-03/nemo_log_globalrank-6_localrank-6.txt\n",
      "Conformer-CTC-Char1/2023-03-10_16-48-03/nemo_log_globalrank-3_localrank-3.txt\n",
      "Conformer-CTC-Char1/2023-03-10_16-48-03/nemo_log_globalrank-4_localrank-4.txt\n",
      "Conformer-CTC-Char1/2023-03-10_16-48-03/cmd-args.log\n",
      "Conformer-CTC-Char1/2023-03-10_16-48-03/events.out.tfevents.1678466922.ip-10-0-234-219.us-west-2.compute.internal\n",
      "Conformer-CTC-Char1/2023-03-10_16-48-03/lightning_logs.txt\n",
      "Conformer-CTC-Char1/2023-03-10_16-48-03/nemo_log_globalrank-0_localrank-0.txt\n"
     ]
    }
   ],
   "source": [
    "!tar -xvzf model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "62018b6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-98a2f791e912bdc0\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-98a2f791e912bdc0\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./ --host 0.0.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ccbca1-91e7-4299-9d0b-e1b1890cdd87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
